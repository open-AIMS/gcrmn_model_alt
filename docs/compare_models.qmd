---
title: "Comparing models - real data"
author: "Murray Logan"
date: today
date-format: "DD/MM/YYYY"
format:
  html:
    ## Format
    theme: [default, resources/style.scss]
    css: resources/style.css
    html-math-method: mathjax
    ## Table of contents
    toc: true
    toc-float: true
    ## Numbering
    number-sections: true
    number-depth: 3
    ## Layout
    page-layout: full
    fig-caption-location: "bottom"
    fig-align: "center"
    fig-width: 4
    fig-height: 4
    out-width: 500px
    fig-dpi: 72
    tbl-cap-location: top
    ## Code
    code-fold: false
    code-tools: true
    code-summary: "Show the code"
    code-line-numbers: true
    code-block-border-left: "#ccc"
    code-copy: true
    highlight-style: atom-one
    ## Execution
    execute:
      echo: true
      #cache: true
    ## Rendering
    embed-resources: true
crossref:
  fig-title: '**Figure**'
  fig-labels: arabic
  tbl-title: '**Table**'
  tbl-labels: arabic
engine: knitr
## execute:
##   cache: true
jupyter: python3
output_dir: "docs"
documentclass: article
fontsize: 12pt
mainfont: Arial
mathfont: LiberationMono
monofont: DejaVu Sans Mono
classoption: a4paper
bibliography: resources/references.bib
---

```{r}
#| label: setup
#| include: false

knitr::opts_chunk$set(
    cache.lazy = FALSE,
    tidy = "styler"
)
## allow indented chunks
assignInNamespace(".sep.label",
  "^\\ *(#|--)+\\s*(@knitr|----+)(.*?)-*\\s*$",
    ns = "knitr"
)
knitr::read_chunk("../R/process_spatial.R")
knitr::read_chunk("../R/process_benthic_data.R")
knitr::read_chunk("../R/fit_models.R")
knitr::read_chunk("../R/aggregate_models.R")
knitr::read_chunk("../R/helper_functions.R")
## knitr::read_chunk("../python/incomplete_spatial.py")
## remove the indentation from all python chunks that start
## with indentation
codes <- knitr::knit_code$get()
process_chunks <- function(codes) {
  nms <- names(codes)
  wch <- which(startsWith(names(codes), "python"))
  codes1 <- lapply(1:length(codes), function(i) {
    if (i %in% wch) {
      x <- gsub("^ {4}", "", codes[[i]])
    } else {
      x <- codes[[i]]
    }
    x
  })
  names(codes1) <- nms
  codes1
}
knitr::knit_code$set(
  process_chunks(codes)
)

options(tinytex.engine =  'xelatex')
```

```{css, echo=FALSE}
figcaption {
  text-align: left !important;
}
```


## Purpose

The primary purpose of this page is to contrast the ability of various
models to represent the temporal trends of real data from a select set
of Marine Ecosystems Of the World (MEOW). For each MEOW, there will be
modelled trends overlayed onto the raw data. These plots are to permit
those who are familiar with the MEOWs to compare the trends yielded
from different models so as to inform decisions about:

- whether any model types yield trends that are inconsistent with the
  understanding of the experts
- whether the raw data themselves are broadly consistent with
  expectations

The candidate models are:

- `stan` - a bespoke Stan model I wrote for the previous GCRMN report
- `xgboost` - bootstrapped xgboost (boosted regression trees) written
  by Jeremy Wicquart (codes for these models are not presented in this
  document)

## Methods

### Data sources

#### Regions and subregions

The GCRMN regions and subregions polygons were obtained by combining
the polygons of the Marine Ecoregions Of the World
[@Spalding-2007]. The code used to obtain these polygons is publicly
available at <https://github.com/GCRMN/gcrmn_regions>.

#### Coral reef distribution {#sec-coral-reef-distribution}

The Tropical Coral Reefs of the World dataset
[CoralReefsOfTheWorld-2011] developed by the World Resources Institute
(WRI) was used as the coral reef distribution. This dataset consists
of a shapefile of coral reef locations at a 500 m resolution. We
modify the dataset by adding coral reefs in Norfolk Island and by
updating coral reef distribution for the Eastern Tropical Pacific,
where multiple inconsistencies were mentioned by coral reefs experts
in the region.

### Benthic cover indicators

Although numerous ecological variables are measured and monitored
across the world’s coral reefs [@Flower-2017], benthic cover is
arguably the most widely assessed, both spatially and temporally. This
is largely because most benthic cover monitoring methods are
relatively simple, cost-effective, and require limited taxonomic
expertise [@Aronson-1994; @Hill-2004]. Measurements of benthic cover
began prior to 1980 [@Connell-1997; @Dustan-1987], and advances in
survey techniques have had minimal effects on comparability with
historical data. For instance, different approaches such as
point-intercept transects and photo-quadrats generally yield
consistent estimates of benthic cover [@Jokiel-2015].

The comparability of methods enables the integration of datasets from
multiple monitoring programs, allowing temporal trends in benthic
cover to be estimated at large spatial scales. This approach, known as
full data analysis, provides greater precision than other forms of
synthesis such as meta-analyses or systematic reviews
[@Spake-2021]. Unlike meta-analysis, which typically produces a single
effect size, full data analysis facilitates the estimation of complex
temporal dynamics. Furthermore, because it relies directly on raw
data, it incorporates a larger quantity of information than
meta-analyses or systematic reviews, which are constrained to
published results.

Among the wide range of benthic categories used by monitoring
programs, we chose to report five major benthic categories (hard
coral, macroalgae, turf algae, coralline algae, and other
fauna). Unlike the “Status of Coral Reefs of the World: 2020” GCRMN
report [@Souter-2021], we separated algae into three functional
groups - macroalgae, turf algae, and coralline algae (see section
Taxonomic re-categorization, for definitions). This decision was made
to better capture the ecological complexity of coral reefs and to
reflect the distinct functional roles of different algal groups
(Tebbett et al., 2023a).

#### Data integration {#sec-data-integration}

A full data analysis of benthic cover in coral reefs is only feasible
when a homogeneous dataset is available. As no such dataset existed at
the global scale, we first conducted a data integration step prior to
analysis. The objective was to construct a consistent synthetic
dataset of coral reef benthic cover by aggregating multiple
heterogeneous individual datasets. This data integration relied on an
improved version of the workflow developed by @Wicquart-2022
for the “Status of Coral Reefs of the World: 2020” GCRMN report
[@Souter-2021]. Key improvements to the workflow included the
addition of quality checks, which provide stronger guarantees of data
reliability. The data integration workflow applied in this report
consists of five main steps, summarized in @fig-3.3 and described in
detail in the following sections.

::: {.figure #fig-3.3}

![](resources/fig-3.3.jpg){width=500px}

Schematic representation of the five main steps of the data
integration workflow used to construct the synthetic dataset on coral
reef benthic cover. MEOW = Marine Ecoregions of the World
[@Spalding-2007].

:::

#### Data collation

We recontacted data contributors who had participated in the “Status
of Coral Reefs of the World: 2020” GCRMN report [@Souter-2021] to
obtain authorization for data reuse and to update the datasets they
had previously shared. In parallel, we issued an open call for data
contributions in July 2024. Finally, data collation was complemented
by searching for datasets available in scientific articles, data
papers, and coral reef data platforms (e.g., MERMAID), and by inviting
dataset owners to contribute.

The datasets compiled during the data collation step were
heterogeneous in terms of format (e.g., CSV, Excel), structure,
variable names, and measurement units (e.g., meters vs. feet for
depth). To enable integration into a single homogeneous synthetic
dataset, a data standardization step was required. For each dataset,
we developed an R script to apply dataset-specific modifications
according to a predefined structure and set of variables
(@tbl-1). These modifications included merging Excel spreadsheets,
linking primary datasets with associated metadata (e.g., site
coordinates, benthic codes), selecting and renaming variables,
converting units, harmonizing Coordinates Reference Systems (CRS) and
date formats, and deriving benthic cover values from raw observations
such as point-intercept transects or photo-quadrats (@fig-3.3, Step
1).



| Nb | Variable         | Type      | Description                                          |
|----|------------------|-----------|------------------------------------------------------|
| 1  | datasetID        | Factor    | ID of the dataset                                    |
| 2  | region           | Factor    | GCRMN region                                         |
| 3  | subregion        | Factor    | GCRMN subregion                                      |
| 4  | ecoregion        | Factor    | Marine Ecoregion of the World (Spalding et al, 2007) |
| 5  | country          | Factor    | Country                                              |
| 6  | territory        | Character | Territory                                            |
| 7  | locality         | Character | Site name                                            |
| 8  | habitat          | Factor    | Habitat                                              |
| 9  | parentEventID    | Integer   | Transect ID                                          |
| 10 | eventID          | Integer   | Quadrat ID                                           |
| 11 | decimalLatitude  | Numeric   | Latitude (decimal, EPSG:4326)                        |
| 12 | decimalLongitude | Numeric   | Longitude (decimal, EPSG:4326)                       |
| 13 | verbatimDepth    | Numeric   | Depth (m)                                            |
| 14 | year             | Integer   | Four-digit year                                      |
| 15 | month            | Integer   | Integer month                                        |
| 16 | day              | Integer   | Integer day                                          |
| 17 | eventDate        | Date      | Date (YYYY-MM-DD, ISO 8601)                          |
| 18 | samplingProtocol | Character | Method used to acquire the measurement               |
| 19 | recordedBy       | Character | Person who acquired the measurement                  |
| 20 | category         | Factor    | Benthic category                                     |
| 21 | subcategory      | Factor    | Benthic subcategory                                  |
| 22 | condition        | Character | Condition for hard corals                            |
| 23 | phylum           | Character | Phylum                                               |
| 24 | class            | Character | Class                                                |
| 25 | order            | Character | Order                                                |
| 26 | family           | Character | Family                                               |
| 27 | genus            | Character | Genus                                                |
| 28 | scientificName   | Character | Species                                              |
| 29 | measurementValue | Numeric   | Percentage cover                                     |

: Description of variables included in the gcrmndb_benthos synthetic
dataset. Variable names (except region, subregion, ecoregion,
category, subcategory, and condition) follow [DarwinCore
terms](http://dwc.tdwg..org/terms/). Variables 2-13 correspond to
spatial dimensions, variables 14-17 to temporal dimensions, and
variables 20-28 to taxonomic information {#tbl-1}



All data standardization was performed using R scripts, ensuring
transparency of modifications and allowing for subsequent corrections
if errors are identified. Because all R scripts are publicly
available, dataset owners can also verify the changes applied to their
data (see <https://github.com/GCRMN/gcrmndb_benthos>).

Following standardization, each dataset was exported in CSV format,
and all CSV files were then merged into a single raw synthetic dataset
(@fig-3.3, Step 2).

#### Taxanomic re-categorization

During the data standardization step, the raw benthic categories -
those originally defined by the data providers in each dataset - were
stored in the temporary variable organismID. We then used the taxize R
package to automatically retrieve taxonomic information for variables
23 to 28, from the World Register of Marine Species (WoRMS)
database. Subsequently, a CSV file containing all unique raw benthic
categories was exported. Each automatically completed entry was
verified, and any missing taxonomic information was manually added for
variables 20 to 28 (@fig-3.3, Step 3).

When a raw benthic category represented a broad, non-taxonomic
grouping, we completed the variables category and, where possible,
subcategory accordingly. For example, the raw category “turf” was
assigned to category = “Algae” and subcategory = “Turf algae.”

Several specific cases required particular attention during taxonomic
reclassification:

- **Mixed categories**: In this case, we assigned the lowest common
     denominator of the mixed categories. For example, when the raw
     benthic category was “Macroalgae and turf algae,” we classified
     it as “Algae”.

- **Stacked categories**: In this case, we retained the category that
     was above the other. For instance, when the raw benthic category
     was “Algae on dead coral,” we assigned the category to “Algae.”

- **Homonym taxa names**: In this case, we either contacted the data
       provider to replace the ambiguous raw category with a precise
       one during the data standardization step, or we left the
       variable category blank, which subsequently led to the removal
       of the corresponding rows. For example, “Turbinaria” refers
       both to a genus of Scleractinia (corals) and to a genus of
       Fucales (macroalgae). If the data provider was able to clarify
       the intended meaning, the raw category was replaced with a
       specific denomination (e.g., “Turbinaria – Coral”) during the
       standardization step.

- **Unrequired or unintelligible categories**: In this case, we did
     not complete the variable category, which also led to the removal
     of the corresponding rows. Examples include raw benthic
     categories such as “Shadow,” “Other,” or “Unknown.”

When the raw benthic category referred to a taxon (e.g., “Acropora”)
rather than a broad grouping (e.g., “Hard coral”), we completed
variables 23 to 28. To do so, we first verified the spelling of each
raw benthic category using WoRMS and considered updates in taxonomic
classification that may have occurred between the time of data entry
by the providers and the integration process. Within the CSV file, we
then filled in the taxonomic rank corresponding to the raw benthic
category, as well as all higher taxonomic levels (variables 23 to 28
in @tbl-1). For example, for the raw benthic category “coral
acropora,” we entered “Acropora” for the variable genus, “Acroporidae”
for family, and continued this process up to the variable phylum. When
the raw benthic category was taxonomic, the variables category and
subcategory were left empty. These variables were later completed in R
by applying attribution rules derived from the taxonomic variables (23
to 28 in @tbl-1). The rules were as follows:

- **Hard coral**: We assigned category = “Hard coral” when the
     variable order was “Scleractinia” or when the variable family was
     “Milleporidae” or “Helioporidae.” When contributors used the term
     “hard coral” without providing taxonomic information, we also
     assigned category = “Hard coral.” Note that the “Hard coral”
     category excluded dead corals but may have included partially or
     fully bleached corals.

- **Macroalgae**: We assigned category = “Algae” and subcategory =
     “Macroalgae” when the variable class was “Phaeophyceae,”
     “Florideophyceae,” or “Ulvophyceae” and the variable order was
     not “Corallinales.” When contributors used the term “macroalgae”
     without providing taxonomic information, we applied the same
     classification (category = “Algae” and subcategory =
     “Macroalgae”).

- **Coralline algae**: We assigned category = “Algae” and subcategory
     = “Coralline algae” when the variable order was “Corallinales.”
     When contributors used the term “coralline algae” without
     taxonomic detail, we again classified it as category = “Algae”
     and subcategory = “Coralline algae”.

- **Turf algae**: When contributors used the term “turf algae,” we
     assigned category = “Algae” and subcategory = “Turf algae”.

- **Cyanobacteria**: We assigned category = “Algae” and subcategory =
     “Cyanobacteria” when the variable phylum was “Cyanobacteria”.

- **Other fauna**: We assigned category = “Other fauna” when the
     variable phylum was “Porifera,” “Chordata,” “Echinodermata,”
     “Bryozoa,” “Annelida,” “Mollusca,” or “Arthropoda”; when the
     variable order was “Actiniaria,” “Alcyonacea,” “Zoantharia,”
     “Corallimorpharia,” or “Antipatharia”; or when the variable
     subclass was “Octocorallia”.

- **Seagrass**: We assigned category = “Seagrass” when the variable
     phylum was “Tracheophyta”.

Once the recategorization was completed, we merged the table
containing the organismID variable and the newly created variables (20
to 28 in @tbl-1) with the main data table. We then removed the
temporary variable organismID and deleted all rows with missing values
in the variable category. Removing missing values in category did not
affect percentage cover values, although it reduced the total
percentage cover for a sampling unit (e.g., quadrat, transect) to
below 100%. Finally, we aggregated the variable measurementValue by
grouping across all other variables, thereby preventing duplicate
benthic categories within a given sampling unit.

The full recategorization of raw benthic categories into standardized
categories (variables 20 to 28, @tbl-1) is publicly available in
the file “03_tax-recategorisation.csv” on the [gcrmndb_benthos GitHub
repository](https://github.com/GCRMN/gcrmndb_benthos).

#### Spatial attribution

Using site coordinates (from the variables decimalLatitude and
decimalLongitude), we added five spatially related variables to the
dataset (@fig-3.3, Step 4). First, we performed a spatial intersection
to assign the GCRMN “region” and “subregion” variables to each site,
using the GCRMN regions shapefile (GCRMN-2024polygons). We then added
the variable ecoregion by intersecting sites with the Marine
Ecoregions of the World dataset [@Spalding-2007]. Finally, we included
the variables country and territory by referencing the fields
SOVEREIGN1 and TERRITORY1 from the World EEZ v12 dataset
[@Flanders-2023]. Because of the limited spatial resolution of the
World EEZ v12 dataset, some sites located near coastlines fell
slightly outside the EEZ polygons. To minimize missing values for
country and territory, we applied a two-step procedure: we first
intersected sites with the World EEZ v12 dataset, then reprocessed
sites with missing values by performing a second intersection with EEZ
polygons buffered by 1 km.

#### Quality checks {#sec-quality-checks}

Pooling large volumes of data without adequate verification risks
compromising data quality. Previous studies have shown that
insufficient quality control in large synthetic datasets can lead to
biased interpretations of ecological questions [@Augustine-2024]. To
address this issue, we implemented a dedicated step for data quality
assessment (@fig-3.3, Step 5). We established a set of nine quality
checks, adapted from @Vandepitte-2015 (@tbl-2). Each
quality check was formulated as a question linked to one or more
variables, making them readily translatable into code.

+----+----------------+-----------------------------------------------------------------------------------------------------------------------+
| Nb | Variable       | Question                                                                                                              |
+====+================+=======================================================================================================================+
|1	 |decimalLatitude |Are the latitude and longitude available?                                                                              |
|    |decimalLongitude|                                                                                                                       |	
+----+----------------+-----------------------------------------------------------------------------------------------------------------------+
|2	 |decimalLatitude |Is the latitude within its possible boundaries (i.e. between -90 and 90)?                                              |
+----+----------------+-----------------------------------------------------------------------------------------------------------------------+
|3   |decimalLongitude|Is the longitude within its possible boundaries (i.e. between -180 and 180)?                                           |
+----+----------------+-----------------------------------------------------------------------------------------------------------------------+
|4   |decimalLatitude |Is the site within the coral reef distribution area (100 km buffer)?                                                   |
|    |decimalLongitude|	                                                                                                                      |
+----+----------------+-----------------------------------------------------------------------------------------------------------------------+
|5   |decimalLatitude |Is the site located within a GCRMN region?                                                                             |
|    |decimalLongitude|       	                                                                                                              |
+----+----------------+-----------------------------------------------------------------------------------------------------------------------+
|6   |decimalLatitude |Is the site located within an EEZ (1 km buffer)?                                                                       |
|    |decimalLongitude|                                                                                                                       |
+----+----------------+-----------------------------------------------------------------------------------------------------------------------+
|7   |year            |Is the year available?                                                                                                 |
+----+----------------+-----------------------------------------------------------------------------------------------------------------------+
|8   |measurementValue|Is the sum of the percentage cover of benthic categories within the sampling unit greater than 0 and lower than 100?   |
+----+----------------+-----------------------------------------------------------------------------------------------------------------------+
|9   |measurementValue|Is the percentage cover of a given benthic category (i.e. a row) greater than 0 and lower than 100?                    |
+----+----------------+-----------------------------------------------------------------------------------------------------------------------+

: List of quality checks used for the gcrmndb_benthos synthetic dataset. {#tbl-2}

Because of rounding decimal places, the sum of percentage cover values
for benthic categories within a sampling unit can slightly exceed 100%
[@Razak-2024]. To avoid unnecessary data loss, we normalized
rows where the total percentage cover was between 100 and 101 to a
maximum of 100. This adjustment was applied prior to implementing
quality check 8 (@tbl-2).

We evaluated each quality check as either “True” or “False,” and
removed all rows that failed at least one check. However, correcting
errors is preferable to deleting data, in order to preserve sufficient
data for analysis. To support error correction, we generated summary
reports for each dataset integrated into the synthetic dataset. These
reports detailed the percentage of rows removed per quality check,
allowing us to identify and correct errors by updating the data
standardization code (@fig-3.3, Step 1). For example, a common and
easily corrected error was the inversion of decimalLatitude and
decimalLongitude.

In addition, the individual dataset reports provided descriptive
information such as the proportion of missing values per variable, the
percentage of rows by benthic category and taxonomic level, and the
spatial and temporal distribution of observations.

#### Missing zeros 

The original supplied data were mostly positive only
records.  That is, a taxa was only recorded when it was present.  In
many locations, it is very rare for a dataset not to register any
values in a major benthic categories (Hard coral, Algae and
Macroalgae) for each sampling unit (e.g. transect) when a survey is
conducted.  However, in other locations if a particular benthic
category is relatively rare or else in low abundance (e.g. Macroalgae
in some places), if only positive observations are recorded the
compiled data may appear to have only sparse data.  This will result
in a upward bias in the cover estimates (and uncertainty) for this
benthic category.

In order to "fill in" these "missing zeros", we can add zero
percentage cover records at the replicate level (typically transects)
for each absent benthic category within any datasets and years where
it is determined that the transect was surveyed (based on the presence
of other benthic categories).  Implicit in this operation is the
assumption that if a transect was surveyed, observers had the chance
to record each taxa and only did not if it was not present.



### Bayesian hierarchical model

#### Modelling considerations

The sampling design of most monitoring programs is typically tailored
somewhere in a spectrum between a configuration of perpetually fixed
sampling sites and a configuration of randomly selected sites,
depending on the purpose, resources and logistics of the program.
Whist fixed sites act as their own baselines over time and thus
provide relatively efficient means for estimating temporal trends, the
resulting estimates are biased towards the selected locations (which
may not be collectively representative of the broader area). By
contrast, a configuration of uniquely random sites each year is less
likely to be biased (hence more representative) and yet usually
requires considerably higher numbers of sites in order to detect
temporal signals from within the noise.

The focus and challenge for the current report is to utilise a
collection of datasets from a large number of disparate monitoring
programs from around the world in order to provide estimates of status
and trends at much broader spatio-temporal scales.

Whenever multiple data sets are integrated together (particularly if
each is used to represent different areas), the issues of
representativeness and bias are exasperated.  Firstly, quantitative
estimates are always driven by sample sizes.  Within any well designed
monitoring program, efforts are made to ensure the design remains
relatively balanced.  However, this is not the case across programs.
Therefore, when aggregating multiple datasets up to a broader scale,
it is important to be able to control for varying samples sizes so as
to minimise the risks of biasing towards the more heavily replicated
data sets.  Moreover, sample size and density does not necessarily
reflect the density and distribution of the underlying landscape.  For
example, in the case of coral reefs, sampling intensity is likely to
be a function of the relative prosperity of the surrounding
populations and proximity to major population centers rather than the
density and distribution of the reefs themselves.

Enormous (and complex) spatio-temporal models that employ full
positional encoding to evaluate the spatial
patterns\footnote{auto-correlative structures} between all possible
pairs of sampling units (sites) have the potential to allow the
transferal of information from the fine, observation level
measurements to the broader levels of this report. By assuming that a
response (such as percentage live hard coral cover) varies
continuously over an entire two-dimensional surface, such models are
potentially able to leverage trends in areas of relatively high sample
density to estimate the trends in neighbouring areas of sparse
sampling density - albeit with greater uncertainty. However such
models proved to be too computationally burdensome and were incredibly
difficult to tune to ensure they yield sensible outcomes. They also
assumed that changes over space were relatively gradual and thus, can
easily smooth over what would otherwise be considered abrupt local
changes. Furthermore, incorporating information about the spatial
distribution of reefs as well as physical barriers to auto-correlative
process are far from trivial.

As an alternative, we explored hierarchical models in which sampling
units are progressively aggregated with their neighbours into larger
and larger units.  For example, neighbouring quadrats are grouped
together into sites, sites into global grid locations (see below) and
so on up to the level of the whole globe.  This represents a
pseudo-spatial model in that although the influence of neighbouring
data does deteriorate along the hierarchy, it does so in increments
relating to group membership rather than as a continuous function of
spatial distance. Hence in the case of an area comprising of ten
sub-areas, each of the sub-areas will share some information with the
other sub-areas even though any one of them might be geographically
closer to a member of another area than most of the sub-areas in its
designated area (the classic nearest vs average neighbour conundrum).
In any case, all attempts to fit full, global hierarchical models with
the very disparate datasets proved very difficult to stabilise.

Instead, smaller hierarchical models (see @fig-schematichierarchy),
fit separately to each MEOW Ecoregion, were integrated together within
a spatially weighted aggregation hierarchy in which individual model
posteriors (annual estimates) were propagated up through the
hierarchy. Although this approach does still have some elements of the
pseudo-spatial hierarchy that permits data poor areas to leverage
patterns off data richer areas, the leveraging is quarantined to
within MEOW Ecoregions where processes are more likely to be
homogeneous and thus the resulting trends are more likely to be
consistent with the observed data. More details about the spatial
weights are discussed in section @sec-weights and the statistical
models are discussed in section @sec-models.


```{tikz}
%| label: fig-schematichierarchy
%| engine: tikz
%| eval: false
%| echo: false
%| class: tikz
%| out-width: 600px
%| fig-cap: Schematic representation of the a) individual MEOW Ecoregion Bayesian modelling hierarchies and b) spatial aggregation hierarchy.  Note the quadrat-level is de-emphasized to highlight that not all data sources include this unit of observation.  The $\omega$ symbolise the use of spatial weights.
%| engine-opts:
%|   template: "resources/tikz-standalone.tex"

\usetikzlibrary{shapes,arrows,shadows,positioning,mindmap,backgrounds,decorations, calc,fit, decorations.pathreplacing,decorations.pathmorphing, shadings,shapes.geometric, shapes.multipart,patterns}

\tikzstyle{labelText} = [font={\fontspec[Scale=1]{inconsolata}}]
\tikzstyle{Messy} = [decorate,decoration={random steps,segment length=3pt, amplitude=0.3pt},thick]
\begin{tikzpicture}[edge from parent/.style={draw,latex-,Messy,anchor=north},
% parent anchor=south, child anchor=north,
level 1/.style={sibling distance = 3cm, level distance = 0.2cm},
level 2/.style={sibling distance = 3cm, level distance = 1.2cm},
level 3/.style={sibling distance = 1.5cm, level distance = 1.5cm},
every tree node/.style={align=north,anchor=north}
]
\draw [fill=black!0] (-7cm,0.2cm) -- ++(12cm,0cm) -- ++(0cm,-9cm) -- ++(-12cm,0cm) -- ++(0cm,9cm);
\node [labelText, anchor=north west] at(-7,0) {a)};
\path
node {}
child {node [labelText] (E1) {Ecoregion} edge from parent[draw=none]
child {node [labelText] (L1) {Tile 1}
child {node [labelText] (S1) {S1}
child {node [labelText,text=black!30] (Q1){Q1}
child {node [labelText] (Y) {
\begin{tabular}{c}
1\\.\\.\\.\\
\end{tabular}
}}
}
child {node [labelText,text=black!20] (Q2){Q2}
}
}
child {node [labelText] {S2}}
edge from parent node [left=1mm] {$\omega_{t_1}$}
}
child {node [labelText] {Tile 2}
child {node [labelText] {S1}}
edge from parent node [right] {$\omega_{t_2}$}
}
child {node [labelText] {Tile 3}
child {node [labelText] {S1}}
child {node [labelText] {S2}}
child {node [labelText] {S3}
}
edge from parent node [right] {$\omega_{t_3}$}
}
};
\draw [anchor=west] ($(L1.west) + (-3.1cm,0)$) node [labelText] (Location) {Grid Tile};
\draw [dashed] (Location) -- (L1);
\draw [anchor=west] ($(Location.west |- S1.center)$) node [labelText] (Site) {Site};
\draw [dashed] (Site) -- (S1);
\draw [anchor=west] ($(Location.west |- Q1.center)$) node [labelText,text=black!30] (Quadrat) {Quadrat};
\draw [dashed,draw=black!30] (Quadrat) -- (Q1);
\draw [anchor=west] (Location.west |- Y.center) node [labelText] (Year) {Year};
\path [draw, Messy,decorate, decoration={brace, amplitude=8pt}] (Y.south west) -- (Y.north west);

\begin{scope}[xshift=4.5cm,yshift=-4.2cm,
level 1/.style={sibling distance = 1cm, level distance = 0.2cm},
level 2/.style={sibling distance = 1.5cm, level distance = 1.2cm},
level 3/.style={sibling distance = 2.0cm, level distance = 1.5cm}
]
\draw [fill=black!5] (-7cm,0.2cm) -- ++(9.0cm,0cm) -- ++(0cm,-9cm) -- ++(-9.0cm,0cm) -- ++(0cm,9cm);
\node [labelText, anchor=north west] at(-7,0) {b)};
\path
node {}
child {node [labelText] (G1) {Global} edge from parent[draw=none]
child{node [labelText] (R1) {R1}
child{node [labelText] (SR1) {SR1}
child{node [labelText] (E1) {E1}
child {node [labelText] (Y) {
\begin{tabular}{c}
1\\.\\.\\.\\
\end{tabular}
}}
edge from parent node [left] {$\omega_{e_1}$}
}
child{node [labelText] (E2) {E2}
edge from parent node [right] {$\omega_{e_2}$}
}
edge from parent node [left] {$\omega_{s_1}$}
}
child{node [labelText] (SR2) {SR2}
edge from parent node [right] {$\omega_{s_2}$}
}
edge from parent node [left] {$\omega_{r_1}$}
}
child{node [labelText] (R2) {R2}
edge from parent node [pos=0.7,right] {$\omega_{r_2}$}
}
child{node [labelText] (R3) {R3}
edge from parent node [right] {$\omega_{r_3}$}
}
};
\draw [anchor=west] ($(R1.west) + (-4.9cm,0)$) node [labelText] (Region) {\begin{minipage}[h]{1.5cm}GCRMN\\ Region\end{minipage}};
\draw [dashed] (Region) -- (R1);
\draw [anchor=west] ($(Region.west |- SR2.center)$) node [labelText] (Subregion) {\begin{minipage}[h]{2cm}GCRMN\\Subregion\end{minipage}};
\draw [dashed] (Subregion) -- (SR1);
\draw [anchor=west] ($(Region.west |- E1.center)$) node [labelText] (Ecoregion) {\begin{minipage}[h]{2cm}MEOW\\Ecoregion\end{minipage}};
\draw [dashed] (Ecoregion) -- (E1);
\draw [anchor=west] (Region.west |- Y.center) node [labelText] (Year) {Year};
\path [draw, Messy,decorate, decoration={brace, amplitude=8pt}] (Y.south west) -- (Y.north west);
\draw [dashed] (Year) -- ($(Y) +(-10mm,0)$);
\end{scope}

\end{tikzpicture}

```

::: {.figure #fig-schematichierarchy}
![](resources/schematicHierarchy-1.png){width=600px}

Schematic representation of the a) individual MEOW Ecoregion Bayesian
modelling hierarchies and b) spatial aggregation hierarchy.  Note the
quadrat-level is de-emphasized to highlight that not all data sources
include this unit of observation.  The $\omega$ symbolise the use of
spatial weights.
:::


#### Spatial hierarchy

The pseudo-spatial hierarchy outlined above necessitates incremental
jumps in scale from the level at which observations are collected up
to the Global (or even regional) scale.  <!--That is, it is necessary
to group the spatial units up incrementally into larger and large
spatial groups (hence the previously described hierarchy).--> If the
jumps are too large, the information (temporal patterns) shared across
neighbouring spatial units might be driven by very different
underlying conditions and thus not appropriate.

The original datasets collated in this study were provided at scales
of either quadrat/transect or spatial aggregations thereof.  These can
be naturally grouped into sites (or individual reefs) as the first
incremental scale jump, however, subsequent increments are less obvious.

There are numerous ways of grouping coral reef locations into broader
geographic areas, or from the other direction, dividing the globe up
spatially. Some candidates include: Exclusive Economic Zones
[@EEZ-2019], Venon Ecoregions [@Veron-2000] or Marine Ecosystems of
the World
[@Spalding-2007]\footnote{https://www.worldwildlife.org/publications/marine-ecoregions-of-the-world-a-bioregionalization-of-coastal-and-shelf-areas}.
Consensus amongst a large panel of coral reef regional representatives
was that Marine Ecosystems of the World (hereafter MEOW) global
classification system were the most appropriate as it has a strong
bio-geographic focus capturing important, community, evolutionary,
dispersal and isolation processes [@Spalding-2007]. The MEOW
Ecoregions were further grouped up into GCRMN sub-regions and regions
(see tables in the Subregion and Region level outputs) and Figures
@fig-schematichierarchy & @fig-schematic) to provide additional
modelling and reporting granularity.

::: {.figure #fig-schematic}
![](resources/schematic_final_version.png){width=600px}

Schematic diagram illustrating the hierarchical structure relating the
hypothetical observations (bottom layer) to the level of a 10x10km
grid tile, MEOW Ecoregions, GCRMN Regions and Global scale. The grid
tile layer depicts the 10x10km tile containing reef (red) and the
voronoi polygons (blue lines) used to partition area zones of sample
unit influence. The MEOW Ecoregions layer illustrates five fictitious
Ecoregions which are aggregated into two GCRMN Regions in the layer
above. Vertical lines illustrate the aggregation of data along the
hierarchy and the numbers along these paths represent the aggregation
weights (also tabulated).
:::


The jump in spatial scale from Site (reef) to MEOW Ecoregion can be
very large and span a wide range of influential processes and drivers.
We therefore sought an additional intermediate scale.  Such a scale
could be based on collections of reefs or broad communities, however
such information was not universally available.  An intermediate scale
could also be achieved by gridding the globe up into an array (grid)
of cells or tiles or a constant size.  Moreover, the use of grid tiles
provides a way of abstracting away design differences between fixed
and random annual site selections - and thus a mechanism by which
multiple sampling designs can be incorporated in the one model.

#### Spatial weights {#sec-weights}

In order to help maximise the chances that the hierarchical
aggregations are reflective of broad spatial patterns and not heavily
biased by sampling effort alone, the aggregations must be weighted by
the proportion of reef area represented by each spatial unit.

Estimating the distribution and quantity of global coral reefs is a
challenging problem.  As is the case with sampling effort consistency
across the globe, the granularity and accuracy of coral reef mapping
varies substantially from region to region, Hence, we sought a
potentially less biased and more uniform method of estimating reef
area.

##### Tropical Coral Reefs of the World

As an alternative to the Allen Atlas, Tropical Coral Reefs of the
World [@Burke-2011; @WRI-2011] digital shapefiles were used to estimate the
amount of coral reef.  The intermediate spatial scale between observed
sites and MEOWs was provided by generating a 10x10km grid of tiles
across the entire globe and assigning a unique identifier to each
tile.

###### Tile level weights

All observed site level locations were assigned to an grid tile on the
basis of nearest neighbour within 10km. To estimate the amount of reef
area within each MEOW that was represented by each of the observed
sites, voronoi polygons were generated from the unique site locations
and overlayed onto the grid (see @fig-voronoi). The reef area
associated with each voronoi cell were then expressed as a proportion
of the total MEOW reef area, thereby representing the relative weight
that each grid tile should carry in the analyses.

::: {.figure #fig-voronoi}
![](resources/voronoi-1.png){width=600px}

Illustration of voronoi polygons overlayed on the 10x10km grid and
reefs (grey). Shaded grid tiles represent grid tiles containing
observed sites and hue of the grid tile shading represents the
relative weights (proportion of reef area in each grid tile).
:::


###### Larger scale weights

The weights (relative contributions) of each MEOW Ecoregion in
aggregating up to GCRMN Sub-regions was calculated as the proportion
of MEOW reef area within each GCRMN Sub-region (see @fig-weights).
Similarly, GCRMN Sub-region and Region weights (used in aggregations
to GCRMN Region and Global levels respectively) were calculated from
the respective proportions of reef areas in GCRMN Regions and
Globally.

::: {.figure #fig-weights}
![](resources/weights_final_version.png){width=600px}

Illustration of the relative reef area represented by each 10x10km
grid tile within three MEOW Ecoregions. The hue of reef fill is
proportional to the relative area of reef in the MEOW.
:::



#### Statistical model {#sec-models}

Live hard coral cover and algal cover were calculated by summing
observation level data across associated taxonomic groupings.

Separate MEOW Ecosystem Bayesian hierarchical models were constructed
within the stan statistical modelling platform [@Carpenter-2017-2017]
via the rstan [@rstan-2025] interface. Each model comprised a model
matrix representing year dumpy coded as cell means contrasts, a model
matrix representing Dataset coded as sum to zero contrasts as well as
varying effects representing the hierarchical structure of Sites
nested within grid tiles ([@fig-schematichierarchy]a).
Weights were also applied to the grid tiles in order to allow the
influence of each grid tile to be proportional to the relative area of
reef each grid tile represented.

Separate models were fitted to explore trends in live hard coral cover
(HCC) and algae cover (A).  In each case, cover was modelled against a
beta distribution (logit link).  Cover values of either 0 or 1 were
first shrunk by 0.01 for compatibility with the beta distribution.
Weakly informative priors were applied to the beta shape parameters as
well as the varying effects parameters and their standard deviations.

In order to impute missing year combinations and smooth over
short-term oscillations in estimates resulting from short-term
fluctuations in sampling designs and data availability, priors on Year
effects (except that associated with the first observed year of data
in a MEOW Ecoregion) were weakly informative normal priors centred
around the posterior of either previous Year (in the case of Years
after the initial observed year) or after (in the case of Years prior
to the initial observed year).  For the initial observed Year,
standard (zero centred) weakly informative priors were applied.

The Dataset effects were included to act as proxies for all the many
and varying ways that different datasets differ including depth,
sampling unit type (quadrats, transects, etc) and observer experience.
Weakly informative normal priors were applied to the Dataset
effects.

The statistical models can be summarised as:

<!--
\begin{align}
  \mathbf{Y} &\sim Beta(\mu\phi, (1-\mu)\phi)\\
  logit(\mu) &= \mathbf{\beta_y} \mathbf{X_y} + \mathbf{\gamma_d} \mathbf{X_d} + \omega\mathbf{\gamma_t} Z_t +
    \mathbf{\gamma_s} Z_s + \mathbf{\gamma_r} Z_r\\
  \mathbf{\gamma_t} &= \sigma_t\times z_t\\
  \mathbf{\gamma_s} &= \sigma_s\times z_s\\
  \mathbf{\gamma_r} &= \sigma_r\times z_r\\
  \phi &\sim \Gamma(0.01,0.01)\\
  z_t,z_s,z_r &\sim N(0,1)\\
  \sigma_t,\sigma_s,\sigma_r &\sim t(3, 0, 1)\\
  \sigma_y &\sim t(3, 0, 0.5)\\ 
  \mathbf{\beta_{y}} &\sim N(\mathbf{y}, \sigma_y)\\ 
  \mathbf{y} &\begin{cases}y=I_y, \sim N(O_y, \sigma_y)\\
     y<I_y, \sim N(\mathbf{y}_{y+1}, 0.1)\\
     y=I_y, \sim N(\beta_{y+1}, 0.1)\\
     y=D_y, \sim N(\mathbf{y}_{y-1}, \sigma_y)\\
     y=G_{ys}, \sim N((\beta_{y-1} + \mathbf(y}_{y+1})/2, 0.1)\\
     y=G_{y}, \sim N((\mathbf{y}_{y-1} + \mathbf{y}_{y+1})/2, 0.1)\\
     y=G_{ye}, \sim N((\mathbf{y]_{y-1} + \beta_{y+1})/2, 0.1)\\
     y=F_y, \sim N(\beta_{y+1}, 0.1)\\
     y>F_y, \sim N(\mathbf{y}_{y+1}, 0.1)
  \end{cases}\\
  \mathbf{\gamma_d} = \mathbf{gamma_raw_d} - \bar{\mathbf{gamma_d}}\\
  \mathbf{\gamma_raw_d} & \sim N(0, 0.1)\\
\end{align}

where:

- $\mathbf{Y}$ is a vector of the cover of the benthic group
  (e.g. either live hard coral, macroalgae, algae, etc)

- $\mathbf{\beta_y}$ and $\mathbf{X_y}$ represent the effects of Year
  and cell-means (no intercept) Year model matrices respectively.

- $\mathbf{\gamma_d}$ and $\mathbf{X_d}$ represent the effects of
  Dataset ID and the associated model matrix.

- $\mathbf{\gamma_d}$ is mean centered to ensure it sums-to-zero so
  that the $\beta$ parameters apply to the average Dataset (rather
  than the first level).

- $\mathbf{\gamma_g}$, $\mathbf{\gamma_s}$ and $\mathbf{\gamma_r}$ are
  the sum-to-zero varying effects

- $Z_g$, $Z_s$ and $Z_r$ represent the Grid_id, Site and
  Transect/Replicate codes respectively.

- $\mathbf{y}$ represents year hyperparameters and $y$ is a year
  iterator.

- $I_y$ and $O_y$ represent the initial observed year and mean
  observed response within the MEOW Ecoregion.

- $G_{ys}$, $G_{y} and $G_{ye}$ represent the years marking the start,
  middle and end of a temporal gap within the observed data for the
  MEOW Ecoregion

- $F_{y}$ represents the final observed year within the MEOW Ecoregion

- Weakly informative priors (on the link scale) are applied to the
  $\sigma$ hyperpriors as well as $\gamma$ (dataset effects).

- Since \mathbf{Y} are hyperpriors on the expected $\beta$ and are
  based on lags from surrounding estimates, the priors had narrower
  spread so as to offer some regularisation in the expected change in
  cover over a single year.

- Simularly, the prior on the sum-to-zero effect of Dataset ID
  ($gamma$) was more informative since there were numerous incidences
  in which different Datasets did not overlap in space and/or time.
  Hence without less weak priors, there was a strong possibility of
  the models doubling up on trying to account for differences in
  Datasets, space and time resulting in highly inflated uncertainties.



-->

\begin{align}
  \mathbf{Y} &\sim Beta(\mu\phi, (1-\mu)\phi)\\
  logit(\mu) &= \mathbf{\beta_y} \mathbf{X_y} + \mathbf{\gamma_d} \mathbf{X_d} + \omega\mathbf{\gamma_t} Z_t +
    \mathbf{\gamma_s} Z_s + \mathbf{\gamma_r} Z_r\\
  \mathbf{\gamma_t} &= \sigma_t\times z_t\\
  \mathbf{\gamma_s} &= \sigma_s\times z_s\\
  \mathbf{\gamma_r} &= \sigma_r\times z_r\\
  \phi &\sim \Gamma(0.01,0.01)\\
  z_t,z_s,z_r &\sim N(0,1)\\
  \sigma_t,\sigma_s,\sigma_r &\sim t_3(0, 1)\\
  \sigma_y &\sim t_3(0, 0.5)\\ 
  \mathbf{\beta_{y}} &\sim N(\mathbf{y}, \sigma_y)\\ 
  \mathbf{y} &\begin{cases}
     y<I_y, \sim N(\mathbf{y}_{y+1}, 0.1)\\
     y=I_y, \sim N(\beta_{y+1}, 0.1)\\
     y=D_y, \sim N(\mathbf{y}_{y-1}, \sigma_y)\\
     y=G_{ys}, \sim N((\beta_{y-1} + \mathbf{y}_{y+1})/2, 0.1)\\
     y=G_{y}, \sim N((\mathbf{y}_{y-1} + \mathbf{y}_{y+1})/2, 0.1)\\
     y=G_{ye}, \sim N((\mathbf{y]_{y-1} + \beta_{y+1})/2, 0.1)\\
     y=F_y, \sim N(\beta_{y+1}, 0.1)\\
     y>F_y, \sim N(\mathbf{y}_{y+1}, 0.1)
  \end{cases}\\
  \mathbf{\gamma_d} & \sim N(0, 0.1)\\
\end{align}

where: 

- $\mathbf{Y}$ is a vector of the cover of the benthic group
  (e.g. either live hard coral, macroalgae, algae, etc)

- $\mathbf{\beta_y}$ and $\mathbf{X_y}$ represent the effects of Year
  and cell-means (no intercept) Year model matrices respectively.

- $\mathbf{\gamma_d}$ and $\mathbf{X_d}$ represent the effects of
  Dataset ID and the associated model matrix such that the $\beta$
  parameters apply to the average Dataset (rather than the first
  level).

- $\mathbf{\gamma_d}$ is mean centered to ensure it sums-to-zero so
  that the $\beta$ parameters apply to the average Dataset (rather
  than the first level).

- $\mathbf{\gamma_g}$, $\mathbf{\gamma_s}$ and $\mathbf{\gamma_r}$ are
  the sum-to-zero varying effects

- $Z_g$, $Z_s$ and $Z_r$ represent the Grid_id, Site and
  Transect/Replicate codes respectively.

- $\mathbf{y}$ represents year hyperparameters and $y$ is a year
  iterator.

- $I_y$ and $O_y$ represents the initial observed year and mean
  observed response within the MEOW Ecoregion.

- $G_{ys}$, $G_{y}$ and $G_{ye}$ represent the years marking the start,
  middle and end of a temporal gap within the observed data for the
  MEOW Ecoregion

- $F_{y}$ represents the final observed year within the MEOW Ecoregion

- Weakly informative priors (on the link scale) are applied to the
  $\sigma$ hyperpriors as well as $\gamma_d$ (dataset effects).

- Since \mathbf{Y} are hyperpriors on the expected $\beta$ and are
  based on lags from surrounding estimates, the priors had narrower
  spread so as to offer some regularisation in the expected change in
  cover over a single year.

- Simularly, the prior on the sum-to-zero effect of Dataset ID
  ($\gamma$) was more informative since there were numerous incidences
  in which different Datasets did not overlap in space and/or time.
  Hence without less weak priors, there was a strong possibility of
  the models doubling up on trying to account for differences in
  Datasets, space and time resulting in highly inflated uncertainties.

Estimates of annual benthic cover thereafter comprised of inverse-link
transformed $\beta$ estimates for the years for which there were
observed data and $\mathbf{Y}$ estimates were used to fill in the gaps
(years for which there were no observed data).  This methodology
enabled us to generate cover estimates that were unsmoothed for data
years (thereby permitting rapid change) whilst still providing
estimates of cover during the temporal gaps that transitioned between
the bookends of the gaps and with uncertainty increasing distal to the
bookends.

An alternate version in which annual benthic cover is derived from
inverse-link transformed $\mathbf{y}$ values is also provisioned.  As
this version uses the generative year hyperpriors, it effectively
applies running one-year smooth over the estimates.

<!-- Trends in hard coral cover to algae ratio (HCC:A)
employed structurally very similar models to those described above,
yet the ratio was modelled against a Gaussian distribution.  -->

All models were run with 10000 no-u-turn MCMC iterations, a warmup of
5000 and a thinning rate of 10 for each of three chains (each with
random initial values). The adaptive delta was elevated to 0.99 to
reduce the incidences of post-warmup divergences.  Diagnostics
indicated that all chains converged on stable, well mixed posteriors
(Rhat values < 1.05) and low MCMC sample auto-correlation (< 0.2).

#### Hierarchical aggregation

The full posteriors for the Year effects (on the logit scale) of each
MEOW Ecoregion were averaged together within each GCRMN Sub-region
([@fig-schematichierarchy]b).  The resulting posteriors were
then summarised by back-transforming to the response scale (inverse
logit transform in the case of beta models) and calculating the means
and highest probability density intervals (80\% and 95\%).  Similarly,
the un-standardised GCRMN Sub-region posteriors were aggregated (with
weights) up to GCRMN Region and then Global level
(see [@fig-schematichierarchy]b & [@fig-schematic]).

#### Code availability

All scripts used to pre-process and analyse the data via the Bayesian
Hierarachical models as well as perform aggregations and derived
tables/figures in this report are available at
<https://github.com/open-AIMS/gcrmn_model_alt>.

### (Bootstrapped) xgboost (boosted regression tree) model

<!--
Jeremy Wicquart has developed an xbgoost model that incorporates a
suite of environmental covariates in addition to space and time.  The
outputs of these models (at each of ecoregion, subregion and region)
were provided in a single spreadsheet and are presented along side the
Bayesian Hierarchical models in the sections below.
-->

Over the past three decades, numerous studies have assessed temporal
trends in the percentage cover of hard corals and other benthic
categories at broad spatial scales. Most of these studies aggregated
data from multiple monitoring programs and interpreted trends by
plotting mean annual hard coral cover together with associated
confidence intervals [e.g. @Gardner-2003; @Obura-2017]. Other studies
applied statistical models to investigate the factors driving temporal
variation in percentage cover [@Bruno-2007; @Death-2012;
@Jackson-2014; @Tebbett-2023b].

The main assumption underlying these approaches is that the aggregated
data are representative of the coral reefs within the region of
interest. However, coral reef monitoring is highly heterogeneous in
both space and time [@Souter-2021]. Some reefs, often located
near research facilities, have been intensively monitored, whereas
others, particularly those in remote areas, remain largely
unmonitored. As a result, calculating mean annual cover at the global
scale risks producing benthic cover trends that are not representative
of the world’s coral reefs as a whole, but instead reflect changes
occurring at monitoring sites.

One way to address this bias is to use predictors to estimate benthic
cover temporal trends in areas with limited or no observed
data. Predictors - also referred to as covariates or explanatory
variables - are variables (e.g., sea surface temperature) that can be
incorporated into statistical models to estimate a response variable
(e.g., hard coral cover). By modeling the relationship between benthic
cover measured at monitoring sites and the corresponding predictor
values, it becomes possible to predict benthic cover at unmonitored
coral reef sites based on their predictor values. Achieving accurate
predictions requires using a large number of predictors, each of which
must contain different information.

For many years, the use of predictors in statistical models for
macro-ecological studies was constrained by their limited availability
at large spatial scales and by coarse spatio-temporal resolution. In
recent years, however, numerous data products - often derived from
satellite observations - have become publicly accessible
[@Gorelick-2017]. Combined with advances in computational power and
Machine Learning (ML) algorithms [@Rubbens-2023], this has enabled the
integration of multiple predictors to estimate benthic
cover. Accordingly, ML-based modeling approaches are increasingly
being applied in coral reef studies [e.g. @Bakker-2023;
@McClanahan-2024].


In this study, we applied a ML approach to estimate temporal trends in
the percentage cover of five major benthic categories (hard coral,
macroalgae, turf algae, coralline algae, and other fauna) on world’s
coral reefs from 1980 to 2024. The six main steps of the ML workflow
are summarized in @fig-3.4 and described in detail in the following
sections. These sections follow the REFORMS checklist [@Kapoor-2024],
which provides guidance for reporting ML-based research.

::: {.figure #fig-3.4}

![](resources/fig-3.4.png){width=500px}

Main steps of the machine learning (ML) modeling approach used to
estimate temporal trends in the percentage cover of five major benthic
categories (hard coral, macroalgae, turf algae, coralline algae, and
other fauna) on the world’s coral reefs from 1980 to 2024. y denotes
the observed percentage cover values (i.e., _measurementValue_ in
Table 3.2) for a given benthic category; pred. represents the set of
predictors used in the ML model; and $\hat{y}$ indicates the predicted
percentage cover values for a given benthic category across coral reef
sites.

:::

#### Preprocessing

##### Data selection

We extracted benthic cover monitoring data from the gcrmndb_benthos
synthetic dataset (see @sec-data-integration).  As this report
focuses on the status and trends of shallow coral reefs, we retained
surveys conducted at depths of 0–30 m [@Rocha-2018]. Surveys with
missing depth information were retained to minimize data loss.  In
addition, some sites not flagged as erroneous during the quality
checks of the data integration step (see @sec-quality-checks)
were removed at this stage based on recommendations from data
contributors.

After applying these selection criteria, the dataset used for modeling
comprised 265 individual datasets, representing 87,701 surveys
conducted across 37,799 sites between 1973 and 2025 (**Table
1.3.1**). Although we modeled benthic cover trends from 1980 to 2024, we
included observed data from 1970 to 2025 for model training in order
to maximize the dataset size. The number of sites varied among benthic
categories, as not all monitoring programs surveyed all categories
included in this report. The full list of datasets used per region is
provided in **Supplementary Table 1**.

##### Exploratory data analysis {#sec-exploratory-data-analysis}

We conducted an exploratory data analysis on the benthic cover dataset
to identify potential inconsistencies that could bias model
predictions.

We plotted and visually inspected the distribution of percentage cover
values (from the variable `measurementValue`) for each benthic
category across both datasets (`datasetID`) and maritime areas. When
distributions differed notably from those observed in other datasets
or areas, we systematically reviewed the corresponding R scripts used
for data standardization to ensure that these discrepancies were not
the result of data integration errors.

Particular attention was given to the presence of zero values in the
`measurementValue` variable. In the context of coral reef benthic
cover, removing zero values can lead to biased temporal trends by
overestimating the mean percentage cover of certain categories.

Together with the quality control procedures applied during data
integration (see @sec-quality-checks), this exploratory data
analysis provided an additional means of verifying the overall
reliability and consistency of the data

#### Data transformation

The final pre-processing step consisted of preparing the dataset for
use in the modeling analyses. For each sampling unit (i.e., site,
transect, or quadrat), percentage cover values were summed for each of
the five major benthic categories. To ensure consistency across
datasets, the average benthic cover per transect was then calculated,
thereby reducing the influence of semi-quantitative photo-quadrat
datasets (e.g., those with a limited number of observation points).

#### Selection of sites to predict {#sec-selection-of-sites-to-predict}

To be able to get estimations of benthic categories’ percentage cover
over sites representative of coral reefs of the world, and not on
sites where monitoring data were available, it was necessary to select
sites on which predictions would be made. To this end, we randomly
sampled 20,000 sites across the world’s coral reefs using a modified
version of the Tropical Coral Reefs of the World dataset
[@CoralReefsOfTheWorld-2011; see @sec-coral-reef-distribution]. The
number of sites was generated proportionally to the extent of the
reefs in each ecoregion so that at least one site was sampled for each
of them. Although the number of sites selected may seem low, each site
was later repeated for each year from 1980 to 2024, which means that
each model must have predicted almost a million rows (see
@sec-predictions). @fig-3.5 compares the spatial distribution of sites
with observed data with those selected for making predictions using
the example of Cuba. Although we assumed that the coral reef
distribution shapefile used for this purpose provides a representative
depiction of the true spatial distribution of coral reefs within the
region, we acknowledge that this working hypothesis may not hold true,
particularly at finer spatial scales.

::: {.figure #fig-3.5}

![](resources/fig-3.5.png){width=500px}

Comparison of the spatial distributions of sites with observed data
and sites used for making predictions, using Cuba as an example. In
the left panel figure, coral reef distribution is represented in light
blue

:::


#### Extraction of predictors

We derived a total of 26 predictors, encompassing various
environmental and anthropogenic dimensions: six related to spatial
characteristics, one to temporal variation, three to hurricane regime,
twelve to thermal regime, two to water quality, and two to direct
human influence. These predictors were used both to train and test the
models based on sites with observed data and to generate predictions
for selected sites (see @sec-selection-of-sites-to-predict). The
complete list of predictors included in the modeling framework, along
with their corresponding data sources, is provided below.



::: {.callout-note collapse=true}
#### Show data source information

1.	`decimalLatitude`

- **Category**: Spatial

- **Data source**: gcrmndb_benthos (training) / Tropical Coral Reefs of
  the World [@CoralReefsOfTheWorld-2011] (prediction)

- **Spatial resolution**: Unknown, but variable (training) / 500 m
  (prediction)

- **Temporal resolution**: None

- **Description**: The latitude of the site

- **Percentage of missing values**: 0% (training/testing) and 0%
  (prediction)

2. `decimalLongitude`

- **Category**: Spatial

-	**Data source**: gcrmndb_benthos / Tropical Coral Reefs of
  the World [@CoralReefsOfTheWorld-2011] 

-	**Spatial resolution**: Unknown, but variable / 500 m

-	**Temporal resolution**: None

-	**Description**: The longitude of the site

-	**Percentage of missing values**: 0% (training/testing) and 0% (prediction)

3. `verbatimDepth`

-	**Category**: Spatial

- **Data source**: gcrmndb_benthos / Tropical Coral Reefs of
  the World [@CoralReefsOfTheWorld-2011] 

-	**Spatial resolution**: Unknown, but variable / 500 m

-	**Temporal resolution**: None

-	**Description**: The longitude of the site

-	**Percent	Data source**: gcrmndb_benthos / None

-	**Spatial resolution**: Unknown, but variable

-	**Temporal resolution**: None

-	**Description**: The depth at which the survey was conducted

-	**Percentage of missing values**: 14.5% (training/testing) and 100% (prediction)

4. `year`

-	**Category**: Temporal

-	**Data source**: gcrmndb_benthos / Generated

-	**Spatial resolution**: None

-	**Temporal resolution**: None

-	**Description**: The year at which the measurement of percentage cover was done

-	**Percentage of missing values**: 0% (training/testing) and 0% (prediction)

5. `windspeed_y1`

-	**Category**: Hurricane regime

-	**Data source**: International Best Track Archive for Climate Stewardship (IBTrACS) Version 4 (Knapp et al., 2010)

-	**Spatial resolution**: 0.1° (~10 km)

-	**Temporal resolution**: 3 hourly (interpolated, most raw data are 6 hourly)

-	**Description**: Maximum sustained wind speed of cyclones passed within 1° (~ 111 km) from the site during the year preceding year i

-	**Percentage of missing values**: 11% (training/testing) and 7% (prediction)

6. `nb_cyclones_y1`

-	**Category**: Hurricane regime

-	**Data source**: International Best Track Archive for Climate Stewardship (IBTrACS) Version 4 (Knapp et al., 2010)

-	**Spatial resolution**: 0.1° (~10 km)

-	**Temporal resolution**: 3 hourly (interpolated, most raw data are 6 hourly)

-	**Description**: Number of cyclones passed within 1° (~ 111 km) from the site during the year preceding year i

-	**Percentage of missing values**: 11% (training/testing) and 7% (prediction)

7. `cyclones_freq`

-	**Category**: Hurricane regime

-	**Data source**: International Best Track Archive for Climate Stewardship (IBTrACS) Version 4 (Knapp et al., 2010)

-	**Spatial resolution**: 0.1° (~10 km)

-	**Temporal resolution**: 3 hourly (interpolated, most raw data are 6 hourly)

-	**Description**: Annual frequency of cyclones that passed within 1° (~ 111 km) of the site during the period 1980-2024

-	**Percentage of missing values**: 11% (training/testing) and 7% (prediction)

8. `elevation`

-	**Category**: Spatial

-	**Data source**: Shuttle Radar Topography Mission (SRTM) Digital Elevation Data Version 4

-	**Spatial resolution**: 90 m

-	**Temporal resolution**: None (one-shot)

-	**Description**: Mean (above-sea) elevation from a 30 km radius from the site

-	**Percentage of missing values**: 0.03% (training/testing) and 0% (prediction)

9. `reefextent`

-	**Category**: Spatial

-	**Data source**: Allen Coral Atlas (ACA) Geomorphic Zonation and Benthic Habitat Version 2.0 (Lyons et al., 2024)

-	**Spatial resolution**: 5 m

-	**Temporal resolution**: None (one-shot)

-	**Description**: Total area of coral reef habitat from a 10 km radius from the site

-	**Percentage of missing values**: 0.03% (training/testing) and 0% (prediction)

10.	`land`

-	**Category**: Spatial

-	**Data source**: Shuttle Radar Topography Mission (SRTM) Digital Elevation Data Version 4

-	**Spatial resolution**: 90 m

-	**Temporal resolution**: None (one-shot)

-	**Description**: Total land area from a 30 km radius from the site

-	**Percentage of missing values**: 0.03% (training/testing) and 0% (prediction)

11.	`gravity`

-	**Category**: Human influence

-	**Data source**: [@Cinner-2018]

-	**Spatial resolution**: 10 km

-	**Temporal resolution**: None (one-shot)

-	**Description**: Gravity value on the site. Gravity can be seen as a proxy of direct human impact on coral reefs and is calculated from human population and reef accessibility 

-	**Percentage of missing values**: 22% (training/testing) and 8% (prediction)

12.	`enso`

-	**Category**: Thermal regime

-	**Data source**: Nino 3.4 Index

-	**Spatial resolution**: None

-	**Temporal resolution**: Monthly

-	**Description**: Average Nino 3.4 Index monthly values over the last two years from the year i

-	**Percentage of missing values**: 2.3% (training/testing) and 4.4% (prediction)

13.	`sst_sd`

-	**Category**: Thermal regime

-	**Data source**: NOAA CDR Optimum Interpolation Sea Surface Temperature (OISST) Version 2.1 

-	**Spatial resolution**: 27,830 m

-	**Temporal resolution**: Daily (from 1981-09-01)

-	**Description**: Long-term SST standard deviation on the site, derived from 1981 to 2024 daily SST values

-	**Percentage of missing values**: 5.1% (training/testing) and 6.3% (prediction)

14.	`sst_skewness`

-	**Category**: Thermal regime

-	**Data source**: NOAA CDR Optimum Interpolation Sea Surface Temperature (OISST) Version 2.1 

-	**Spatial resolution**: 27,830 m

-	**Temporal resolution**: Daily (from 1981-09-01)

-	**Description**: Long-term SST skewness on the site, derived from 1981 to 2024 daily SST values

-	**Percentage of missing values**: 5.1% (training/testing) and 6.3% (prediction)

15.	`sst_max`

-	**Category**: Thermal regime

-	**Data source**: NOAA Coral Reef Watch [@Skirving-2020]

-	**Spatial resolution**: 5,000 m

-	**Temporal resolution**: Yearly (from 1985)

-	**Description**: Maximum annual SST values on the site for the year i

-	**Percentage of missing values**: 10.1% (training/testing) and 11.3% (prediction)

16.	`sst_max_y1`

-	**Category**: Thermal regime

-	**Data source**: NOAA Coral Reef Watch [@Skirving-2020]

-	**Spatial resolution**: 5,000 m

-	**Temporal resolution**: Yearly (from 1985)

-	**Description**: Maximum annual SST values on the site for the year i-1. This lagged version of the predictor “sst_max” was included to take into account the time needed for the percentage cover to be impacted by the event(s).

-	**Percentage of missing values**: 10.1% (training/testing) and 13.5% (prediction)

17.	`sst_mean`

-	**Category**: Thermal regime

-	**Data source**: NOAA Coral Reef Watch [@Skirving-2020]

-	**Spatial resolution**: 5,000 m

-	**Temporal resolution**: Yearly (from 1985)

-	**Description**: Mean annual SST values on the site for the year i

-	**Percentage of missing values**: 10.1% (training/testing) and 11.3% (prediction)

18.	`sst_mean_y1`

-	**Category**: Thermal regime

-	**Data source**: NOAA Coral Reef Watch [@Skirving-2020]

-	**Spatial resolution**: 5,000 m

-	**Temporal resolution**: Yearly (from 1985)

-	**Description**: Mean annual SST values on the site for the year  i-1. This lagged version of the predictor “sst_mean” was included to take into account the time needed for the percentage cover to be impacted by the event(s).

-	**Percentage of missing values**: 10.1% (training/testing) and 13.5% (prediction)

19.	`sst_min`

-	**Category**: Thermal regime

-	**Data source**: NOAA Coral Reef Watch [@Skirving-2020]

-	**Spatial resolution**: 5,000 m

-	**Temporal resolution**: Yearly (from 1985)

-	**Description**: Minimum annual SST values on the site for the year i

-	**Percentage of missing values**: 10.1% (training/testing) and 11.3% (prediction)

20.	`ssta_mean`

-	**Category**: Thermal regime

-	**Data source**: NOAA Coral Reef Watch [@Skirving-2020]

-	**Spatial resolution**: 5,000 m

-	**Temporal resolution**: Yearly (from 1985)

-	**Description**: Mean annual SST anomaly values on the site for the year i

-	**Percentage of missing values**: 10.1% (training/testing) and 11.3% (prediction)

21.	`ssta_max`

-	**Category**: Thermal regime

-	**Data source**: NOAA Coral Reef Watch [@Skirving-2020]

-	**Spatial resolution**: 5,000 m

-	**Temporal resolution**: Yearly (from 1985)

-	**Description**: Maximum annual SST anomaly values on the site for the year i

-	**Percentage of missing values**: 10.1% (training/testing) and 11.3% (prediction)

22.	`dhw_max`

-	**Category**: Thermal regime

-	**Data source**: NOAA Coral Reef Watch [@Skirving-2020]

-	**Spatial resolution**: 5,000 m

-	**Temporal resolution**: Yearly (from 1986)

-	**Description**: Maximum Degree Heating Week (DHW) value on the site for the year i

-	**Percentage of missing values**: 10% (training/testing) and 13.5% (prediction)

23.	`dhw_max_y1`

-	**Category**: Thermal regime

-	**Data source**: NOAA Coral Reef Watch [@Skirving-2020]

-	**Spatial resolution**: 5,000 m

-	**Temporal resolution**: Yearly (from 1986)

-	**Description**: Maximum Degree Heating Week (DHW) value on the site for the year  i-1. This lagged version of the predictor “dhw_max” was included to take into account the time needed for the percentage cover to be impacted by the event(s).

-	**Percentage of missing values**: 10% (training/testing) and 15.7% (prediction)

24.	`chla_mean`

-	**Category**: Water quality

-	**Data source**: Ocean Color SMI: Standard Mapped Image MODIS Aqua Data

-	**Spatial resolution**: 4,616 m

-	**Temporal resolution**: Unknown

-	**Description**: Long-term average of chlorophyll a concentration (in mg/m3) from a 10 km radius from the site from 2002-01-01 to 2022-12-31.

-	**Percentage of missing values**: 2.6% (training/testing) and 4.3% (prediction)

25.	`chla_sd`

-	**Category**: Water quality

-	**Data source**: Ocean Color SMI: Standard Mapped Image MODIS Aqua Data

-	**Spatial resolution**: 4,616 m

-	**Temporal resolution**: Unknown

-	**Description**: Long-term standard deviation of chlorophyll a concentration (in mg/m3) from a 10 km radius from the site from 2002-01-01 to 2022-12-31.

-	**Percentage of missing values**: 2.6% (training/testing) and 4.3% (prediction)

26.	`population`

-	**Category**: Human influence

-	**Data source**: Gridded Population of the World (GPW) Version 4.11

-	**Spatial resolution**: 927.67 m

-	**Temporal resolution**: Yearly (for years 2000, 2005, 2010, 2015, and 2020). Missing values for the years 2000–2024 were estimated using a linear model.

-	**Description**: Total number of inhabitants living within 5 km from the site on the year i

-	**Percentage of missing values**: 4.8% (training/testing) and 44.4% (prediction)

:::


After extracting the predictor values, we examined the number of
missing values for each predictor and each year. This control step
aimed to identify potential issues in the extraction process that
could result in an abnormally high number of missing values, thereby
reducing the amount of usable information available for models
development (i.e. training and testing) and prediction.  The
performance of GBM models is generally unaffected by the inclusion of
non-informative predictors, as these models inherently perform feature
selection during training [@Kuhn-2013]. Feature selection involves
identifying and removing highly correlated predictors, which represent
redundant sources of information [@Boehmke-2019]. Although this step
is not strictly necessary for GBM models, we examined the Pearson
correlation coefficients among all predictors using pairwise linear
regressions and excluded variables with correlation coefficients
greater than 0.90 or lower than –0.90. This optional procedure was
implemented primarily to reduce model computation time. As a result of
this process, the predictor `sst_mean_y1` was removed, leaving a total
of 25 predictors used in the final models.

The high predictive potential of ML models is often constrained by
data availability, particularly the ability to integrate a sufficient
number of predictors at adequate spatio-temporal resolutions. Not all
factors known to influence the percentage cover of benthic categories
can be incorporated into the modeling framework due to data
limitations. For instance, although Stony Coral Tissue Loss Disease
(SCTLD) has been identified as a major driver of hard coral mortality
in the Caribbean [@Alvarez-Filip-2022], the scarcity of
monitoring programs quantifying SCTLD prevalence prevents its
inclusion as a predictor variable.

Beyond data availability, the spatio-temporal resolution of predictors
also represents a critical limitation. We assumed that the extracted
predictor values accurately reflected in situ conditions - those that
would have been measured directly at a given site and time. However,
we acknowledge that the resolution of some predictors is insufficient
to capture small-scale variability. For example, substantial
differences in sea surface temperature (SST) may occur within a single
5 km x 5 km pixel [@Green-2019], which corresponds to the spatial
resolution of NOAA’s CoralTemp dataset [@Skirving-2020]. Moreover, by
definition, SST data do not account for temperature variations with
depth, which can nevertheless be considerable [@Leichter-2006].

#### Machine learning models

Machine learning encompasses a wide range of methods (e.g., support
vector machines, random forests) that can be applied to classification
or regression tasks (Boehmke and Greenwell, 2020). Among these, we
selected Gradient Boosting Machines (GBM, also referred to as Boosted
Regression Trees), and specifically the XGBoost algorithm, due to its
high predictive performance [@Boehmke-2019; Chen-2025].

Contrary to other modelling approaches such as Bayesian models, like
the one used for the “Status of Coral Reefs of the World: 2020” GCRMN
report [@Souter-2021], ML models are not intrinsically built to
consider uncertainty [@Rubbens-2023]. However, confidence intervals
can be estimated for ML models using bootstrap. Bootstrapping consists
of sampling randomly the initial dataset with replacement, to produce
variability within the new dataset [@Boehmke-2019]. This means that
the number of initial rows remained the same, but that some rows were
either removed, present one time, or duplicated (one or several times)
into the new dataset, due to the sampling. For the purpose of this
report, we used a stratified bootstrap per datasetID. This was done to
obtain more representative confidence intervals and stabilize
estimates. This approach also helps limit the impact that adding new
datasets or removing existing ones may have on the results.

A key challenge in ML is overfitting, where a model performs extremely
well on the training dataset but poorly on new, unseen data
[@Kuhn-2013].  A common strategy to reduce overfitting is to partition
the dataset into a training set and a testing set. The training set is
used to fit the model, while the testing set is used to evaluate
predictive accuracy on independent data. For this study, we applied a
75/25 split, assigning 75% of observations (i.e., rows) to the
training dataset and 25% to the testing dataset.

In addition, GBM models include multiple hyperparameters that must be
tuned to optimize predictive performance and limit overfitting. Model
tuning involves identifying the best combination of hyperparameters
that maximize predictive accuracy. For each bootstrap iteration, we
tested 10 combinations of five hyperparameters: learning rate, number
of trees, tree depth, minimum observations per leaf, and loss
reduction. The learning rate (also referred to as shrinkage) controls
the step size during gradient descent; the number of trees specifies
the ensemble size; tree depth defines the maximum number of levels in
each tree; minimum observations per leaf sets the smallest number of
observations required to form a terminal node; loss reduction (also
known as gamma) sets the structural complexity of the trees. The 10
hyperparameter combinations were selected to ensure broad coverage of
the hyperparameter space (i.e., maximizing entropy). Model performance
during hyperparameter tuning was assessed using 3-fold
cross-validation on the training dataset.

We fitted 20 ML models, one corresponding to a bootstrap iteration,
for each of the five major benthic categories (hard coral, macroalgae,
turf algae, coralline algae, and other fauna), by training the model
on a new dataset, generated through bootstrapping. Although we could
have kept the same hyperparameters from one bootstrap iteration to
another, which would have saved a lot of computation time, we decided
to rerun the hyperparameter tuning at each iteration to stabilize the
model results.

#### Model evaluation

##### Model performance

The Root Mean Square Error (RMSE) is the most common metric used to
evaluate the performance of ML regression models. Since RMSE is
expressed in the same unit as the variable predicted, it represents an
easy-to-interpret metric [@Kuhn-2013]. For example, a RMSE
value of 5 means that the value predicted by the model differed, on
average, by 5 percent of hard coral cover. Hence, the lower the RMSE
value, the better the model’s predictive performance. We calculated
the RMSE as follows:

$$
\mathrm{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2}
$$

where $n$ is the number of observations, $y_i$ is the observed value
$i$, and $\hat{y}_i$ the predicted value i. In addition to the RMSE,
we also calculated the R² (also known as R-squared or coefficient of
determination), which is a widely used metric in statistics,
particularly for linear regression. R² is usually interpreted as the
proportion of the information from the data that is explained by the
model [@Kuhn-2013]. For example, an R² of 0.80 indicates that the
model explains 80% of the variation of the data. We calculated R² as
follows:

$$
R^2 = 1 - \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{\sum_{i=1}^n (y_i - \bar{y})^2}
$$

where $n$ is the number of observations, $y_i$ is the observed value
$i$, $\hat{y}_i$ the predicted value $i$, and $\bar{y} the mean of
observed values. RMSE and R² represent two complementary metrics of
model performance. Indeed, RMSE describes how well the model performs
on average, while R² provides a measure of correlation [@Kuhn-2013].

Metrics for regression models such as RMSE and R² are not sufficient
alone to estimate the performance of a ML model. Indeed, these metrics
provide a single value to evaluate the overall performance of the ML
model and can mask poor predictions over certain ranges of variation
of the variable to be predicted. For this reason, we plotted predicted
versus observed values on the testing dataset and we checked for the
distribution of residuals.

##### Model interpretation

Although ML models are sometimes described as “black box” models,
there exists in fact different tools to interpret these models
[@Biecek-2021; @Boehmke-2019]. We used variable importance plots
[VIMP, see page 207 in @Kuhn-2013] to compare the relative influence
of each predictor on the percentage cover of each of the five major
benthic categories. However, we restricted our interpretations of the
VIMP to model evaluation rather than using them for their explicative
capabilities. Hence, interpretation of VIMP can also be seen as a
third way to control data quality, along with quality checks (see
@sec-quality-checks) and exploratory data analysis (see
@sec-exploratory-data-analysis).

#### Predictions {#sec-predictions}

We predicted values of percentage cover for each of the five major
benthic categories, across 20,000 sites over coral reefs of the
world. For each site, values were predicted for 44 years (i.e. from
1980 to 2024), resulting in a total of 880,000 predictions of
percentage cover values performed by each ML model. These predictions
were obtained for the 20 bootstrap iterations. Because we were
interested in temporal trends at a higher spatial scale than sites, we
averaged the predictions per area or over the entire world, for each
year and each bootstrap iteration. Then, we calculated mean percentage
cover for each of the five major benthic categories, for each year
across the 20 bootstrap iterations. In addition, we calculated the 95%
upper and lower bounds of confidence intervals around the mean by
using the 0.975 and 0.025 quantiles, respectively. The same process
was carried out on the regional and sub-regional scales.


#### Code availability

All scripts used to generate the values, tables, figures, and maps
presented in this report are available at
<https://github.com/GCRMN/global_2024>. Data analyses relying on
Google Earth Engine [@Gorelick-2017] were implemented in
JavaScript. Machine learning models were executed using R scripts on
an RStudio Server hosted on a Google Cloud virtual machine (50 GB
storage, 64 GB RAM, 8 CPUs, Ubuntu). Other R scripts were run on a
Dell Inspiron 7780 personal computer (32 GB RAM, Windows 11). Most
analyses were conducted in R version 4.5.1 [@R-4.5-1], primarily using
the packages tidyverse v2.0.0 [@Wickham-2019], tidymodels v1.3.0
[@Kuhn-2020], and sf v1.0-21 [@Pebesma-2023]. The complete list of R
packages used and their associated versions is provided in the README
file of the GitHub repository.


## Preparations

This document provides code chunks that pertain to the preparation and
analysis of the Bayesian Hierarchical models.  The xgboost model code
is provided and documented elsewehere.

### Spatial layers

::: {.panel-tabset}

#### R

```{r}
#| label: cwd
#| eval: false
#| echo: false
#| warning: false
#| message: false
#| cache: false
getwd()
```

Load the necessary R libraries

```{r}
#| label: spatial libraries
#| output: false
#| eval: true
#| warning: false
#| message: false
#| cache: false
```

Establish the global environment and paths

```{r}
#| label: spatial global parameters
#| results: hide
#| eval: true
#| echo: true
#| cache: false
```

:::


:::: {.panel-tabset}

#### World map layers

::: {.panel-tabset}

##### R

```{r}
#| label: ne countries
#| eval: false
#| echo: true
#| warning: false
#| message: false
#| cache: false
```

:::

#### Reef grid

::: {.panel-tabset}

##### R

```{r}
#| label: reef grid
#| eval: false
#| echo: true
#| warning: false
#| message: false
#| cache: false
```

:::

#### Ecoregions (MEOWs)

::: {.panel-tabset}

##### R

```{r}
#| label: ecoregions
#| eval: false
#| echo: true
#| warning: false
#| message: false
#| cache: false
```

:::

#### Ecoregion lookup

::: {.panel-tabset}

##### R

```{r}
#| label: ecoregion lookup
#| eval: false
#| echo: true
#| warning: false
#| message: false
#| cache: false
```

:::


::::


#### Process spatial data

:::: {.panel-tabset}

##### Reef grid

::: {.panel-tabset}

###### R

```{r}
#| label: process grid reef
#| eval: false
#| echo: true
#| warning: false
#| message: false
#| cache: false
```

:::

##### Join MEOWs and lookup

::: {.panel-tabset}

###### R

```{r}
#| label: join meow and ecoregion_lookup
#| eval: false
#| echo: true
#| warning: false
#| message: false
#| cache: false
```

:::

##### Process spatial weights

::: {.panel-tabset}

###### R

```{r}
#| label: process patial weights
#| eval: false
#| echo: true
#| warning: false
#| message: false
#| cache: false
```

:::


::::



### Benthic data

::: {.panel-tabset}

#### R

Load the necessary R libraries

```{r}
#| label: spatial libraries
#| output: false
#| eval: true
#| warning: false
#| message: false
#| cache: false
```

Establish the global environment and paths

```{r}
#| label: processing global parameters
#| results: hide
#| eval: true
#| echo: true
#| cache: false
```

:::

#### Import benthic data

Benthic data

```{r}
#| label: read benthic data
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

Benthic prediction data

```{r}
#| label: read benthic prediction data
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

#### Process benthic data

1. Process benthic data (Part 1. add ecoregions)

```{r}
#| label: process benthic data Part 1. add ecoregions
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

2. Process benthic data (Part 2. add grid data)

```{r}
#| label: process benthic data Part 2. add grid data
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

3. Process benthic data (Part 3. add factors)

```{r}
#| label: process benthic data Part 3. add factors
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```




## Modelled trends


::: {.panel-tabset}

### Get ecoregions
Get the names of the ecoregions

```{r}
#| label: get ecoregions
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

### Get all the years

```{r}
#| label: get all years
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

### Set up nest
Set up the nested data for modelling

```{r}
#| label: fit models nest
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

### Refactor subsets

```{r}
#| label: fit models refactor
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

### Prepare data for STAN

```{r}
#| label: prepare data for stan function
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

```{r}
#| label: fit models prepare for stan
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

### STAN code (gcrmn_model.stan)

```{R}
#| label: fit models stan code
#| echo: false
cat(readLines("../R/gcrmn_model_43.stan"), sep = "\n")
```

### Fit STAN models

```{r}
#| label: fit models stan
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

### Extract posterior predictions

```{r}
#| label: fit models stan posterior predictions
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

:::

In each of the following sections:

- the dark blue line represents the mean of the cover estimates
  (bootstrapped xgboost model)
- the blue band represents the 95% interval of cover estimates
  (bootstrapped xgboost model)
- the white line represents the posterior median of cover estimates
  (Bayesian Heirarchical model)
- the darkest orange band represents the 80% credibility interval of
  cover estimates (Bayesian Heirarchical model)
- the orange band represents the 95% credibility interval of the
  cover estimates (Bayesian Heirarchical model)
- the light orange band represents the 95% credibility interval of
  cover estimates for years in which there were no observed data in
  the presented spatial scale (e.g. Ecoregion, Subregion or Region)
  (Bayesian Heirarchical model).
- in the case of Subregions and Regions, the light orange band only
  appears for spans of years for which there were no observations
  across all the consistuent spatial units.



<!--
Note, the weights used in the aggregation of the Bayesian Hierarchical
models are recycled from the 2020 GCRMN analysis and need to be
updated.  In particular, the latest version of the data have some
ecoregion (MEOW) differences that mean that some of the 2020
ecoregions are not absent and there are now some ecoregions in the
data that were not present in the 2020 data.  The combinations of
figures listed below are aligned with the ecoregions present in the
2020 report and therefore are missing some ecoregions:

- Amazonia
- Arafura Sea
- Cargados Carajos/Tromelin Island
- Clipperton
- Eastern India
- Guianan
- Halmahera
- Southeast Madagascar
- Western India


And contain some ecoregions for which there are no associated xgboost
models:

- Cocos Islands
- Northern Gulf of Mexico
- Northern Galapagos Islands
- Western Galapagos Islands
-->



### Ecoregion (MEOW) level

::: {.panel-tabset}

#### Modelled trends

Within Ecoregions, temporal (Modelled) trends are represented by four figures:

- top left: Bayesian Hierachical (orange) and xgboost (blue) estimates
  for the entire GCRMN temporal domain overlayed onto observed data

- top right: Bayesian Hierachical (orange) and xgboost (blue)
  estimates for the temporal domain of the observed data for that
  Ecoregion overlayed onto observed data

- bottom left: Bayesian Hierachical (orange) and xgboost (blue) estimates
  for the entire GCRMN temporal domain

- top right: Bayesian Hierachical (orange) and xgboost (blue)
  estimates for the temporal domain of the observed data for that
  Ecoregion

#### Simple mean/median trends

To assist in the evaluation of the models, we have also calculated two
forms of simple summary statistics:

- Simple means/medians represent the means and medians of all
  available observations in the ecoregion per year

- Hierarchical means and medians of the available observed data are
calculated as averages of averages (etc) starting at the
level of Dataset/Replicates/Years -> Dataset/Site/Years -> Dataset/Grid/Years -> Dataset/Years -> Years.

These two alternatives can yield very different estimates.  This
hierachical averaging takes partial account for differences in
Datasets and spatial units.

That said, neither method are as good as statistical models for
representing population trends as they implicitly makes very specific
and arguably unjustified assumptions about the distribution of data
(gaussian) and fail to capture the repeated measurement nature of much
monitoring data.  Also note, that if the locations and methods change
between years, then so too can the sample bias and this results in
inconsistent estimates between years.

Also note, that unlike the models, the simple and hierarchical
means/medians are not weighted by reef area and are instead going to
be heavily driven by sample sizes.

#### Data conditional on Dataset ID

In this section we have produced simple exploratory plots conditioned
on DatasetID so as to get a feel for the temporal distribution of each
dataset.  The smooth trends are simple splines.

#### Data conditional on grid id

In this section we have produced simple exploratory plots conditioned
on grid_id (broad location) so as to get a feel for the temporal
distribution of each location.  The smooth trends are simple splines.

:::


::: {.callout-note collapse=true}
#### Show code

```{r}
#| label: interpolate values function
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

```{r}
#| label: stan partial plot function
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

```{r}
#| label: aggregate_compile
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

```{r}
#| label: aggregate_compile_plots
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```



:::

```{r}
#| label: read aggregate ecoregion plots
#| eval: true
#| echo: false
#| warning: false
#| message: false
#| cache: false
benthic_posteriors_ecoregions <- targets::tar_read("aggregate_ecoregion_plots_", store = "../R/_targets")
```

```{r}
#| label: aggregate ecoregion plots
#| eval: true
#| echo: false
#| output: asis
#| warning: false
#| message: false
#| cache: false
cat("::: {.panel-tabset}\n")
for (reg in sort(unique(benthic_posteriors_ecoregions$region))) {
  dat_reg <- benthic_posteriors_ecoregions |>
    filter(region == reg)
  cat(paste0("#### ", reg, "\n"))
  cat("::: {.panel-tabset}\n")
  for (subreg in sort(unique(dat_reg$subregion))) {
    cat(paste0("###### ", subreg, "\n"))
    dat_subreg <- dat_reg |>
      filter(subregion == subreg)
    cat("::: {.panel-tabset}\n")
    for (eco in sort(unique(dat_subreg$ecoregion))) {
      cat(paste0("###### ", eco, "\n"))
      dat_eco <- dat_subreg |>
        filter(ecoregion == eco)
      cat("::: {.panel-tabset}\n")
      xcats <- levels(forcats::fct_relevel(unique(dat_eco$category), c('Hard coral', 'Macroalgae'))) 
      for (catg in xcats) {
      ## for (catg in sort(unique(dat_eco$category))) {
        cat(paste0("####### ", catg, "\n"))
        dat_cat <- dat_eco |>
          filter(category == catg)

        cat("::: {.panel-tabset}\n")
             
        cat(paste0("######## Modelled trends\n"))
        fig <- dat_cat$plot[[1]]
        fig_V2 <- str_replace(fig, "pdp", "pdp_V2")
        fig1a <- str_replace(fig, "pdp", "pdp_a")
        fig1a_V2 <- str_replace(fig, "pdp", "pdp_a_V2")
        fig2 <- str_replace(fig, "pdp", "pdpraw")
        fig2a <- str_replace(fig, "pdp", "pdpraw_a")
        fig3 <- str_replace(fig, "pdp", "pdprawxgboost")
        fig3_V2 <- str_replace(fig, "pdp", "pdprawxgboost_V2")
        fig3a <- str_replace(fig, "pdp", "pdprawxgboost_a")
        fig3a_V2 <- str_replace(fig, "pdp", "pdprawxgboost_a_V2")
        fig4a_V2 <- str_replace(fig, "pdp", "pdpraw_a_V2")
        fig5a_V2 <- str_replace(fig, "pdp", "pdp_bayes_a_V2")
        ## cat("The left column of figures displays the Bayesian Hierachical smoothed estimates and the right column displays the unsmoothed estimates.\n\n")
        ## cat(paste0(
        ##   "![](", fig3, "){width=400px}", 
        ##   ## "![](", fig5a_V2, "){width=400px}", 
        ##   ## "![](", fig4a_V2, "){width=400px}", 
        ##   "![](", fig3_V2, "){width=400px}\n",
        ##   "![](", fig3a, "){width=400px}",
        ##   "![](", fig3a_V2, "){width=400px}\n",
        ##   "![](", fig, "){width=400px}",
        ##   "![](", fig_V2, "){width=400px}\n",
        ##   "![](", fig1a, "){width=400px}",
        ##   "![](", fig1a_V2, "){width=400px}\n\n"
        ##   ## "![](", fig, "){width=300px}",
        ##   ## "![](", fig1a, "){width=300px}",
        ##   ## "![](", fig3, "){width=300px}",
        ##   ## "![](", fig3a, "){width=300px}\n\n"
        ## ))

       cat('::: {layout="[ 0.49, -0.01, 0.49 ]"}\n\n')
       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig3,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical mode: orange
       ribbon with white line; xgboost: blue ribbon and line) in ", catg , " with overlayed observed data
       (dots) for the ", eco, " GCRMN ecoregion when missing zeros are filled in.  Model estimates based on $\\mathbf{y}$ hyperpriors (and thus mildly smoothed). The orange bands represent
       80% and 95% (darker) credibility intervals.  Grey ribbon represents 
       years for which there are no observed data. Thin grey lines join sampling units that 
       are repeatedly measured over time.\n"))
       cat("::::\n\n")
       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig3_V2,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical mode: orange
       ribbon with white line; xgboost: blue ribbon and line) in ", catg , " with overlayed observed data
       (dots) for the ", eco, " GCRMN ecoregion when missing zeros are filled in.  Model estimates based on $\\beta$ parameters (and thus not smoothed). The orange bands represent
       80% and 95% (darker) credibility intervals.  Grey ribbon represents 
       years for which there are no observed data. Thin grey lines join sampling units that 
       are repeatedly measured over time.\n"))
       cat("::::\n\n")
       cat(":::\n\n")

       cat('::: {layout="[ 0.49, -0.01, 0.49 ]"}\n\n')
       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig3a,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical mode: orange
       ribbon with white line; xgboost: blue ribbon and line) in ", catg , " with overlayed observed data
       (dots) for the ", eco, " GCRMN ecoregion trimmed to the temporal range of the data.  Model estimates based on $\\mathbf{y}$ hyperpriors (and thus mildly smoothed). The orange bands represent
       80% and 95% (darker) credibility intervals.  Grey ribbon represents 
       years for which there are no observed data. Thin grey lines join sampling units that 
       are repeatedly measured over time.\n"))
       cat("::::\n\n")
       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig3a_V2,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical mode: orange
       ribbon with white line; xgboost: blue ribbon and line) in ", catg , " with overlayed observed data
       (dots) for the ", eco, " GCRMN ecoregion when missing zeros are filled in and the date range are trimmed to the temporal range of the data.  Model estimates based on $\\beta$ parameters (and thus not smoothed). The orange bands represent
       80% and 95% (darker) credibility intervals.  Grey ribbon represents 
       years for which there are no observed data. Thin grey lines join sampling units that 
       are repeatedly measured over time.\n"))
       cat("::::\n\n")
       cat(":::\n\n")

       ## cat('::: {layout="[ 0.49, -0.01, 0.49 ]"}\n\n')
       ## cat(":::: {.figure #fig-x}\n")
       ## cat(paste0("![](", fig,"){width=400px}\n\n"))
       ## cat(paste0("Modelled temporal trend (Bayesian Hierarchical mode: orange
       ## ribbon with white line; xgboost: blue ribbon and line) in ", catg , "
       ## for the ", eco, " GCRMN ecoregion when missing zeros are filled in.  Model estimates based on $\mathbf{y}$ hyperpriors (and thus mildly smoothed). The orange bands represent
       ## 80% and 95% (darker) credibility intervals.  Grey ribbon represents 
       ## years for which there are no observed data. \n"))
       ## cat("::::\n\n")
       ## cat(":::: {.figure #fig-x}\n")
       ## cat(paste0("![](", fig_V2,"){width=400px}\n\n"))
       ## cat(paste0("Modelled temporal trend (Bayesian Hierarchical mode: orange
       ## ribbon with white line; xgboost: blue ribbon and line) in ", catg , " 
       ## for the ", eco, " GCRMN ecoregion trimmed to the temporal range of the data having filled in the missing zeros.  Model estimates based on $\mathbf{y}$ hyperpriors (and thus mildly smoothed). The orange bands represent
       ## 80% and 95% (darker) credibility intervals.  Grey ribbon represents 
       ## years for which there are no observed data. \n"))
       ## cat("::::\n\n")
       ## cat(":::\n\n")

       cat('::: {layout="[ 0.49, -0.01, 0.49 ]"}\n\n')
       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig1a,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical mode: orange
       ribbon with white line; xgboost: blue ribbon and line) in ", catg , " trimmed to the temporal range of the data
       for the ", eco, " GCRMN ecoregion when missing zeros are filled in.  Model estimates based on $\\mathbf{y}$ hyperpriors (and thus mildly smoothed). The orange bands represent
       80% and 95% (darker) credibility intervals.  Grey ribbon represents 
       years for which there are no observed data. \n"))
       cat("::::\n\n")
       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig1a_V2,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical mode: orange
       ribbon with white line; xgboost: blue ribbon and line) in ", catg , " trimmed to the temporal range of the data 
       for the ", eco, " GCRMN ecoregion when missing zeros are filled in and the date range is trimmed to the temporal range of the data. Model estimates based on $\\beta$ parameters (and thus not smoothed). The orange bands represent
       80% and 95% (darker) credibility intervals.  Grey ribbon represents 
       years for which there are no observed data. \n"))
       cat("::::\n\n")
       cat(":::\n\n")

        cat(paste0("######## Simple mean/median trends\n"))
        fig5a <- str_replace(fig, "pdp", "raw_pdp_simple") |>
                 str_replace("figures/ecoregion/ecoregion_", "figures/raw/")
        fig6 <- str_replace(fig, "pdp", "pdprawxgboost_a_simple")
        fig6a <- str_replace(fig, "pdp", "pdprawxgboost_a_simple_V2")
        fig7 <- str_replace(fig, "pdp", "pdp_a_simple")
        fig7a <- str_replace(fig, "pdp", "pdp_a_simple_V2")
        ## cat("In each of the following figures, the salmon colored line/points represent the simple hierarchical **means**, the teal coloured line/dots represent the hierarchical **medians**.  The left column of figures displays the Bayesian Hierachical smoothed estimates and the right column displays the unsmoothed estimates.\n\n")
        ## cat(paste0(
        ##   "![](", fig7, "){width=400px}",
        ##   "![](", fig7a, "){width=400px}\n",
        ##   "![](", fig6, "){width=400px}",
        ##   "![](", fig6a, "){width=400px}\n",
        ##   "![](", fig5a, "){width=400px}\n\n"))

       cat('::: {layout="[ 0.49, -0.01, 0.49 ]"}\n\n')
       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig7,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical model: orange
       ribbon with white line; xgboost: blue ribbon and line) and simple and hierarhical summaries (colored dots and lines)
       in ", catg , " for the ", eco, " GCRMN 
       ecoregion trimmed to the temporal range of the data.  Model estimates based on $\\mathbf{y}$ hyperpriors (and thus mildly smoothed).  The orange bands represent 80% and 95% (darker) 
       credibility intervals.  Grey ribbon represents years for which 
       there are no observed data. \n"))
       cat("::::\n\n")
       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig7a,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical model: orange
       ribbon with white line; xgboost: blue ribbon and line) and simple and hierarhical summaries (colored dots and lines)
       in ", catg , " for the ", eco, " GCRMN 
       ecoregion trimmed to the temporal range of the data.  Model estimates based on $\\beta$ parameters (and thus not smoothed).  The orange bands represent 80% and 95% (darker) 
       credibility intervals.  Grey ribbon represents years for which 
       there are no observed data. \n"))
       cat("::::\n\n")
       cat(":::\n\n")

       cat('::: {layout="[ 0.49, -0.01, 0.49 ]"}\n\n')
       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig6,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical model: orange
       ribbon with white line; xgboost: blue ribbon and line), simple and hierarhical summaries (colored dots and lines) and underlayed by the observed data (gray/black dots)
       in ", catg , " for the ", eco, " GCRMN 
       ecoregion trimmed to the temporal range of the data.  Model estimates based on $\\mathbf{y}$ hyperpriors (and thus mildly smoothed).  The orange bands represent 80% and 95% (darker) 
       credibility intervals.  Grey ribbon represents years for which 
       there are no observed data. Thin grey lines join sampling units that 
       are repeatedly measured over time.\n"))
       cat("::::\n\n")
       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig6a,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical model: orange
       ribbon with white line; xgboost: blue ribbon and line), simple and hierarhical summaries (colored dots and lines) and underlayed by the observed data (gray/black dots)
       in ", catg , " for the ", eco, " GCRMN 
       ecoregion trimmed to the temporal range of the data.  Model estimates based on $\\beta$ parameters (and thus not smoothed).  The orange bands represent 80% and 95% (darker) 
       credibility intervals.  Grey ribbon represents years for which 
       there are no observed data. Thin grey lines join sampling units that 
       are repeatedly measured over time.\n"))
       cat("::::\n\n")
       cat(":::\n\n")

       cat('::: {layout="[ 0.49, -0.01, 0.49 ]"}\n\n')
       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig5a,"){width=400px}\n\n"))
       cat(paste0("Observed data (grey/black dots) and simple and hierarhical summaries (colored dots and lines) 
       in ", catg , " for the ", eco, " GCRMN 
       ecoregion trimmed to the temporal range of the data.  Model estimates based on $\\mathbf{y}$ hyperpriors (and thus mildly smoothed).  The orange bands represent 80% and 95% (darker) 
       credibility intervals.  Grey ribbon represents years for which 
       there are no observed data. Thin grey lines join sampling units that 
       are repeatedly measured over time.\n"))
       cat("::::\n\n")
       cat(":::\n\n")
 
        cat(paste0("######## Data conditional on dataset ID\n"))
        fig6a <- str_replace(fig, "pdp", "raw_pdp_datasetID") |>
                 str_replace("figures/ecoregion/ecoregion_", "figures/raw/")
        ## cat("The salmon colored line/points represent the simple hierarchical **means**, the teal coloured line/dots represent the hierarchical **medians**\n\n")
        ## cat(paste0(
        ##   "![](", fig1a_V2, "){width=400px}\n",
        ##   "![](", fig6a, "){width=700px}\n\n"))

       cat('::: {layout="[ 0.49, -0.01, 0.49 ]"}\n\n')
       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig1a_V2,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical model: orange
       ribbon with white line; xgboost: blue ribbon and line), simple and hierarhical summaries (colored dots and lines) and underlayed by the observed data (gray/black dots)
       in ", catg , " for the ", eco, " GCRMN 
       ecoregion trimmed to the temporal range of the data.  Model estimates based on $\\beta$ parameters (and thus not smoothed).  The orange bands represent 80% and 95% (darker) 
       credibility intervals.  Grey ribbon represents years for which 
       there are no observed data.  Thin grey lines join sampling units that 
       are repeatedly measured over time.\n"))
       cat("::::\n\n")

       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig6a,"){width=400px}\n\n"))
       cat(paste0("Observed data (dots) with simple gam smoothers (red ribbon) 
       conditional on datasetID (facets) in ", catg , " for the ", eco, " 
       GCRMN ecoregion.\n"))
       cat("::::\n\n")
       cat(":::\n\n")


        cat(paste0("######## Data conditional on grid ID\n"))
        fig7a <- str_replace(fig, "pdp", "raw_pdp_grid_id") |>
                 str_replace("figures/ecoregion/ecoregion_", "figures/raw/")
        ## cat("The salmon colored line/points represent the simple hierarchical **means**, the teal coloured line/dots represent the hierarchical **medians**\n\n")
        ## cat(paste0(
        ##   "![](", fig1a_V2, "){width=400px}\n",
        ##   "![](", fig7a, "){width=700px}\n\n"
        ##   ))

       cat('::: {layout="[ 0.49, -0.01, 0.49 ]"}\n\n')
       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig6a,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical model: orange
       ribbon with white line; xgboost: blue ribbon and line), simple and hierarhical summaries (colored dots and lines) and underlayed by the observed data (gray/black dots)
       in ", catg , " for the ", eco, " GCRMN 
       ecoregion trimmed to the temporal range of the data.  Model estimates based on $\\beta$ parameters (and thus not smoothed).  The orange bands represent 80% and 95% (darker) 
       credibility intervals.  Grey ribbon represents years for which 
       there are no observed data.  Thin grey lines join sampling units that 
       are repeatedly measured over time.\n"))
       cat("::::\n\n")

       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig7a,"){width=400px}\n\n"))
       cat(paste0("Observed data (dots) with simple gam smoothers (red ribbon) 
       conditional on grid_id (facets) in ", catg , " for the ", eco, " 
       GCRMN ecoregion.\n"))
       cat("::::\n\n")
       cat(":::\n\n")


        cat(":::\n")

      }
      cat(":::\n")
    }
    cat(":::\n")
  }
  cat(":::\n")
}
cat(":::\n")

```


### Subregion level

Subregion level estimates are generated by calculating weighted
averages of Ecoregion posteriors (at the draw level). Weights are
based on relative reef areas of the Ecoregions as calculated from
Coral Reefs of the World spatial layers.

Note, the weights are caculated as the relative reef areas of the
Ecoregions **for which there were observed data**.  There were eight
Ecoregions for which there were no observed/available benthic data for
this installment of the GCRMN report:

- Amazonia
- Arafura Sea
- Cargados Carajos/Tromelin Island
- Clipperton
- Eastern India
- Guianan
- Halmahera
- Ogasawara Islands
- Southeast Madagascar
- Western India

Within Subregions, tremporal trends are represented by two figures:

- top left: Bayesian Hierachical (orange) and xgboost (blue) estimates
  for the entire GCRMN temporal domain 

- top right: Bayesian Hierachical (orange) and xgboost (blue)
  estimates for the temporal domain of the observed data for that
  Subregion

::: {.callout-note collapse=true}
#### Show code

```{r}
#| label: interpolate values function
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

```{r}
#| label: stan partial plot function
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

```{r}
#| label: aggregate_subregions
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

```{r}
#| label: aggregate_subregions_plots
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```



:::

```{r}
#| label: read aggregate subregion plots
#| eval: true
#| echo: false
#| warning: false
#| message: false
#| cache: false
benthic_posteriors_subregions <- targets::tar_read("aggregate_subregion_plots_", store = "../R/_targets")
wts <- targets::tar_read("process_spatial_weights_", store = "../R/_targets") |>
  mutate(GCRMN_region = str_replace(GCRMN_region, "East Asia", "EAS"),
    GCRMN_subregion = str_replace(GCRMN_subregion, "East Asia", "EAS")
  )
wts_subregions <- targets::tar_read("wts_subregions_", store = "../R/_targets") 
summary_subregion <- targets::tar_read("summary_subregion_", store = "../R/_targets")
summary_subregion_V2 <- targets::tar_read("summary_subregion_V2_", store = "../R/_targets")
```

```{r}
#| label: aggregate subregion plots
#| eval: true
#| echo: false
#| output: asis
#| warning: false
#| message: false
#| cache: false
cat("::: {.panel-tabset}\n")
for (reg in sort(unique(summary_subregion$region))) {
  dat_reg <- summary_subregion |>
    filter(region == reg)
  cat(paste0("#### ", reg, "\n"))
  cat("::: {.panel-tabset}\n")
  for (subreg in sort(unique(dat_reg$subregion))) {
    cat(paste0("###### ", subreg, "\n"))
    dat_subreg <- dat_reg |>
      filter(subregion == subreg)
    cat("::: {.panel-tabset}\n")
    xcats <- levels(forcats::fct_relevel(unique(dat_subreg$category), c('Hard coral', 'Macroalgae'))) 
    for (catg in xcats) {
    ## for (catg in sort(unique(dat_subreg$category))) {
      cat(paste0("####### ", catg, "\n"))
      dat_cat <- dat_subreg |>
        filter(category == catg)
      fig <- dat_cat$plot[[1]]
      fig1a <- str_replace(fig, "pdp", "pdp_a")
      fig2 <- str_replace(fig, "pdp", "pdp_V2") 
      fig2a <- str_replace(fig, "pdp", "pdp_a_V2")
      ## cat(paste0(
      ##   ## "![](", fig, "){width=300px}",
      ##   ## "![](", fig1a, "){width=300px}",
      ##   "![](", fig1a, "){width=400px}",
      ##   "![](", fig2a, "){width=400px}\n\n"
      ## )) 

       cat('::: {layout="[ 0.49, -0.01, 0.49 ]"}\n\n')
       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig1a,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical model: orange
       ribbon with white line; xgboost: blue ribbon and line) 
       in ", catg , " for the ", subreg, " GCRMN 
       subregion when missing zeros are filled in. Model estimates on which the aggregated subregion are derived are based on $\\mathbf{y}$ hyperpriors (and thus mildly smoothed).  The orange bands represent 80% and 95% (darker) 
       credibility intervals.  The orange bands represent 80% and 95% (darker) 
       credibility intervals.  Grey ribbon represents years for which 
       there are no observed data.\n"))
       cat("::::\n\n")

       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig2a,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical model: orange
       ribbon with white line; xgboost: blue ribbon and line) 
       in ", catg , " for the ", subreg, " GCRMN 
       subregion when missing zeros are filled in.  Model estimates on which the aggregated subregion are derived are based on $\\beta$ parameters (and thus not smoothed). The orange bands represent 80% and 95% (darker) 
       credibility intervals.  Grey ribbon represents years for which 
       there are no observed data. Thin grey lines join sampling units that 
       are repeatedly measured over time.\n"))
       cat("::::\n\n")

       cat(":::\n\n")

      ## wts |>
      ##   mutate(GCRMN_subregion = str_replace(GCRMN_subregion, "\\.", " ")) |>
      ##   filter(GCRMN_region == reg,
      ##     GCRMN_subregion == subreg) |>
      ##   dplyr::select(Region = GCRMN_region,
      ##     Subregion = GCRMN_subregion,
      ##     Ecoregion = ECOREGION,
      ##     Area = area,
      ##     Weight = wt) |>
    cat("::: {.callout-note collapse=true}\n")
    cat("#### Show aggregation weights\n")
    wts_subregions |>
      filter(region==reg, subregion==subreg) |>
      dplyr::select(Region=region,
        Subregion=subregion,
        Ecoregion=ECOREGION,
        Area=area,
        Weight = wt
      ) |>
        knitr::kable(caption = "Ecoregion (MEOW) reef area and weights applied in the aggregation up to Subregion") |>
        print()
    cat(":::\n")
    cat("::: {.callout-note collapse=true}\n")
    cat("#### Show data behind figure\n")
    summary_subregion_V2 |>
      filter(category == catg, region == reg, subregion == subreg) |>
      _[["cellmeans_trim"]][[1]] |>
      dplyr::select(-variable) |>
      dplyr::mutate(across(c(median, lower, upper, lower_80, upper_80), \(x) round(x * 100, 2))) |>
      knitr::kable(caption = paste0("Estimated annual ", catg, " cover (%) at the subregion scale.")) |>
      print()
    cat(":::\n")
    }
    cat(":::\n")
  }
  cat(":::\n")
}
cat(":::\n")
```

### Region level

Region level estimates are generated by calculating weighted
averages of Subregion posteriors (at the draw level). Weights are
based on relative reef areas of the Subregions as calculated from
Coral Reefs of the World spatial layers.

Within Regions, tremporal trends are represented by two figures:

- top left: Bayesian Hierachical (orange) and xgboost (blue) estimates
  for the entire GCRMN temporal domain 

- top right: Bayesian Hierachical (orange) and xgboost (blue)
  estimates for the temporal domain of the observed data for that
  Region

::: {.callout-note collapse=true}
#### Show code

```{r}
#| label: interpolate values function
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

```{r}
#| label: stan partial plot function
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

```{r}
#| label: aggregate_regions
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

```{r}
#| label: aggregate_regions_plots
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

:::
 
```{r}
#| label: read aggregate region plots
#| eval: true
#| echo: false
#| warning: false
#| message: false
#| cache: false
## benthic_posteriors_regions <- targets::tar_read("aggregate_region_plots_", store = "../R/_targets")
## benthic_posteriors_regions_V2 <- targets::tar_read("aggregate_region_plots_V2_", store = "../R/_targets")
summary_region <- targets::tar_read("summary_region_", store = "../R/_targets")
summary_region_V2 <- targets::tar_read("summary_region_V2_", store = "../R/_targets")
wts_regions <- targets::tar_read("wts_regions_", store = "../R/_targets") 
```

```{r}
#| label: aggregate region plots
#| eval: true
#| echo: false
#| output: asis
#| warning: false
#| message: false
#| cache: false
cat("::: {.panel-tabset}\n")
for (reg in sort(unique(summary_region$region))) {
  dat_reg <- summary_region |>
    filter(region == reg)
  cat(paste0("#### ", reg, "\n"))
  cat("::: {.panel-tabset}\n")
  xcats <- levels(forcats::fct_relevel(unique(dat_reg$category), c('Hard coral', 'Macroalgae'))) 
  for (catg in xcats) {
  ## for (catg in sort(unique(dat_reg$category))) {
    cat(paste0("####### ", catg, "\n"))
    dat_cat <- dat_reg |>
      filter(category == catg)
    fig <- dat_cat$plot[[1]]
    fig1a <- str_replace(fig, "pdp", "pdp_a")
    fig2 <- str_replace(fig, "pdp", "pdp_V2")
    fig2a <- str_replace(fig, "pdp", "pdp_a_V2")
    ## cat(paste0(
    ##   ## "![](", fig, "){width=300px}",
    ##   ## "![](", fig1a, "){width=300px}",
    ##   "![](", fig1a, "){width=400px}",
    ##   "![](", fig2a, "){width=400px}\n\n"
    ##   ))

       cat('::: {layout="[ 0.49, -0.01, 0.49 ]"}\n\n')
       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig1a,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical model: orange
       ribbon with white line; xgboost: blue ribbon and line) 
       in ", catg , " for the ", reg, " GCRMN 
       region when missing zeros are filled in. Model estimates on which the aggregated region are derived are based on $\\mathbf{y}$ hyperpriors (and thus mildly smoothed).  The orange bands represent 80% and 95% (darker) 
       credibility intervals.  The orange bands represent 80% and 95% (darker) 
       credibility intervals.  Grey ribbon represents years for which 
       there are no observed data.\n"))
       cat("::::\n\n")

       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig2a,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical model: orange
       ribbon with white line; xgboost: blue ribbon and line) 
       in ", catg , " for the ", reg, " GCRMN 
       region when missing zeros are filled in.  Model estimates on which the aggregated region are derived are based on $\\beta$ parameters (and thus not smoothed). The orange bands represent 80% and 95% (darker) 
       credibility intervals.  Grey ribbon represents years for which 
       there are no observed data. Thin grey lines join sampling units that 
       are repeatedly measured over time.\n"))
       cat("::::\n\n")

       cat(":::\n\n")


    ## wts |>
    ##   mutate(GCRMN_subregion = str_replace(GCRMN_subregion, "\\.", " ")) |>
    ##   filter(GCRMN_region == reg) |>
    ##   dplyr::select(Region = GCRMN_region,
    ##     Subregion = GCRMN_subregion,
    ##     Area = subregion_area) |>
    ##   group_by(Region, Subregion) |>
    ##   summarise(Area = unique(Area), .groups = "drop") |>
    ##   mutate(wt = Area / sum(Area)) |>
    cat("::: {.callout-note collapse=true}\n")
    cat("#### Show aggregation weights\n")
    wts_regions |>
      filter(region==reg) |>
      dplyr::select(Region=region,
        Subregion=subregion,
        Area=subregion_area,
        Weight = wt
      ) |>
      knitr::kable(caption = "Subregion reef area and weights applied in the aggregation up to Region") |>
      print()
    cat(":::\n")
    cat("::: {.callout-note collapse=true}\n")
    cat("#### Show data behind figure\n")
    summary_region_V2 |>
      filter(category == catg, region == reg) |>
      _[["cellmeans_trim"]][[1]] |>
      dplyr::select(-variable) |>
      dplyr::mutate(across(c(median, lower, upper, lower_80, upper_80), \(x) round(x * 100, 2))) |>
      knitr::kable(caption = paste0("Estimated annual ", catg, " cover (%) at the region scale.")) |>
      print()
    cat(":::\n")

  }
  cat(":::\n")
}
cat(":::\n")
```
 
### Global level

Global level estimates are generated by calculating weighted
averages of Region posteriors (at the draw level). Weights are
based on relative reef areas of the Regions as calculated from
Coral Reefs of the World spatial layers.

::: {.callout-note collapse=true}
#### Show code

```{r}
#| label: interpolate values function
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

```{r}
#| label: stan partial plot function
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

```{r}
#| label: aggregate_global
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

```{r}
#| label: aggregate_global_plots
#| output: false
#| eval: false
#| warning: false
#| message: false
#| cache: false
```

:::

```{r}
#| label: read aggregate global plots
#| eval: true
#| echo: false
#| warning: false
#| message: false
#| cache: false
## benthic_posteriors_global <- targets::tar_read("aggregate_global_plots_", store = "../R/_targets")
## benthic_posteriors_global_V2 <- targets::tar_read("aggregate_global_plots_V2", store = "../R/_targets")
summary_global <- targets::tar_read("summary_global_", store = "../R/_targets")
summary_global_V2 <- targets::tar_read("summary_global_V2_", store = "../R/_targets")
wts_global <- targets::tar_read("wts_global_", store = "../R/_targets") 
```

```{r}
#| label: aggregate global plots
#| eval: true
#| echo: false
#| output: asis
#| warning: false
#| message: false
#| cache: false
cat("::: {.panel-tabset}\n")
## for (reg in sort(unique(benthic_posteriors_regions$region))) {
##   dat_reg <- benthic_posteriors_regions |>
##     filter(region == reg)
##   cat(paste0("#### ", reg, "\n"))
##   cat("::: {.panel-tabset}\n")
  xcats <- levels(forcats::fct_relevel(unique(summary_global$category), c('Hard coral', 'Macroalgae'))) 
  for (catg in xcats) {
  ## for (catg in sort(unique(summary_global$category))) {
    cat(paste0("####### ", catg, "\n"))
    dat_cat <- summary_global |>
      filter(category == catg)
    fig <- dat_cat$plot[[1]]
    fig1a <- str_replace(fig, "pdp", "pdp_a")
    ## fig2 <- str_replace(fig, "pdp", "pdprawxgboost")
    fig2 <- str_replace(fig, "pdp", "pdp_V2")
    fig2a <- str_replace(fig, "pdp", "pdp_a_V2")
    ## cat(paste0(
    ##   ## "![](", fig, "){width=400px}",
    ##   "![](", fig1a, "){width=600px}\n",
    ##   "![](", fig2a, "){width=600px}\n\n"
    ##   ))


       cat('::: {layout="[ 0.49, -0.01, 0.49 ]"}\n\n')
       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig1a,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical model: orange
       ribbon with white line; xgboost: blue ribbon and line) 
       in ", catg , " for the globe when missing zeros are filled in. Model estimates on which the aggregated global estimates are derived are based on $\\mathbf{y}$ hyperpriors (and thus mildly smoothed).  The orange bands represent 80% and 95% (darker) 
       credibility intervals.  The orange bands represent 80% and 95% (darker) 
       credibility intervals.  Grey ribbon represents years for which 
       there are no observed data.\n"))
       cat("::::\n\n")

       cat(":::: {.figure #fig-x}\n")
       cat(paste0("![](", fig2a,"){width=400px}\n\n"))
       cat(paste0("Modelled temporal trend (Bayesian Hierarchical model: orange
       ribbon with white line; xgboost: blue ribbon and line) 
       in ", catg , " for the GCRMN globe 
       when missing zeros are filled in.  Model estimates on which the aggregated global are derived are based on $\\beta$ parameters (and thus not smoothed). The orange bands represent 80% and 95% (darker) 
       credibility intervals.  Grey ribbon represents years for which 
       there are no observed data. Thin grey lines join sampling units that 
       are repeatedly measured over time.\n"))
       cat("::::\n\n")

       cat(":::\n\n")
    ## wts |>
    ##   mutate(GCRMN_subregion = str_replace(GCRMN_subregion, "\\.", " ")) |>
    ##   filter(GCRMN_region == reg) |>
    ##   dplyr::select(Region = GCRMN_region,
    ##     Subregion = GCRMN_subregion,
    ##     Area = subregion_area) |>
    ##   group_by(Region, Subregion) |>
    ##   summarise(Area = unique(Area), .groups = "drop") |>
    ##   mutate(wt = Area / sum(Area)) |>

    cat("::: {.callout-note collapse=true}\n")
    cat("#### Show aggregation weights\n")
    wts_global |>
      dplyr::select(Region=region,
        Area=region_area,
        Weight = wt
      ) |>
      knitr::kable(caption = "Region reef area and weights applied in the aggregation up to Global") |>
      print()
    cat(":::\n")

    cat("::: {.callout-note collapse=true}\n")
    cat("#### Show data behind figure\n")
    summary_global_V2 |>
      filter(category == catg) |>
      _[["cellmeans_trim"]][[1]] |>
      dplyr::select(-variable) |>
      dplyr::mutate(across(c(median, lower, upper, lower_80, upper_80), \(x) round(x * 100, 2))) |>
      knitr::kable(caption = paste0("Estimated annual ", catg, " cover (%) at the global scale.")) |>
      print()
    cat(":::\n")
    
  }
  cat(":::\n")
```

## Codebase

The full code repository can be found at
<https://github.com/open-AIMS/gcrmn_model_alt>.
 
